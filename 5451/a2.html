<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-11-19 Fri 22:28 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>CSCI 5451 Assignment 2: Distributed and Shared Memory Programming</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Chris Kauffman" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<meta name="viewport" content="width=device-width, maximum-scale=1, minimum-scale=1" />
<style type="text/css">
@media screen {
:root {
--heading-bg-color:#e8c62e;
--heading-fg-color:#7a0019;
}
html {
font-family: serif;
text-align: justify;
}
pre.src, pre.example {
overflow-x: scroll;
}
/* Merge subtitle area with title area */
.subtitle {
text-align: center;
margin-top: -2em;
padding-top: 1em;
padding-bottom: 0.1em;
}
.title, .subtitle {
color: var(--heading-fg-color);
background-color: var(--heading-bg-color);
}
/* Section borders, left section header style */
div.outline-2, #table-of-contents {
background-color: rgb(250,250,250);
border: 0.75em solid var(--heading-bg-color);
border-top: 0em;
padding: 0em .5em .5em .5em; /* top right bottom left */
margin: 1em 0em 1em 0em; /* top right bottom left */
}
div.outline-2 > h2, #table-of-contents > h2 {
background-color: var(--heading-bg-color);
color: var(--heading-fg-color);
font-variant: small-caps;
padding: 0em 0em 0em .5em; /* top right bottom left */
margin: 0em -.5em 0em -.75em; /* top right bottom left */
text-align: left;
}
blockquote {
font-style: italic;
}
td, th {
padding-top: 2px;
padding-bottom: 2px;
}
body {
background-color: #EEE;
}
pre {
}
#content, #preamble, #postamble {
margin-left:300px;
}
.tag {
background-color: inherit; font-family: inherit;
padding: inherit; font-size: 80%; font-weight: inherit;
text-transform: uppercase;
}

.figure p { text-align: inherit; }
figure-number { font-style: italic; }
#table-of-contents {
text-align: left;
position: fixed;
left: 0;
margin: 0 auto;
padding: 0;
width: 300px;
top: 0;
height: 100%;
border: 0;
display: block;
}
#text-table-of-contents {
overflow-y: scroll;
height: 100%;
}
#text-table-of-contents ul {
padding-left: 1em;
margin-left: 0.5em;
}
#table-of-contents > h2 {
padding: 0.1em;
margin: 0;
}
/* adjustments for small screen, toc at top only */
@media (max-width: 800px) { /* landscape for iphone */
html {
-webkit-text-size-adjust: none;  /* prevent scaling of text on mobile */
}
body {
background-color: #EEE;
width:100%;
margin:0 auto;
}
#content, #preamble, #postamble {
margin-left:0;
}
#table-of-contents {
position: static;
left: inherit;
width:inherit;
height: auto;
border-top: 0em;
padding: 0em .5em .5em .5em; /* top right bottom left */
margin: 1em 0em 1em 0em; /* top right bottom left */
border: 0.75em solid #006633;
}
div.outline-2, #table-of-contents {
background-color: rgb(250,250,250);
border: 0.75em solid var(--heading-bg-color);
border-top: 0em;
padding: 0em .5em .5em .5em; /* top right bottom left */
margin: 1em 0em 1em 0em; /* top right bottom left */
}
div.outline-2 > h2, #table-of-contents > h2 {
background-color: var(--heading-bg-color);
color: var(--heading-fg-color);
font-variant: small-caps;
padding: 0em 0em 0em .5em; /* top right bottom left */
margin: 0em -.5em 0em -.75em; /* top right bottom left */
text-align: left;
}
#text-table-of-contents {
overflow-y: visible;
height: inherit;
}
#text-table-of-contents ul {
padding-left: 1em;
margin-left: 0.5em;
}
}
.linenr { font-size: xx-small; }
}

@media print {
html {
font-family: serif;
font-size: 10pt;
text-align: justify;
.linenr { font-size: xx-small; }
}
}
</style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="preamble" class="status">
<i>Last Updated: 2021-11-19 Fri 22:28</i>
</div>
<div id="content">
<h1 class="title">CSCI 5451 Assignment 2: Distributed and Shared Memory Programming</h1>
<ul class="org-ul">
<li><b>Due: Wed 12/15/2021 by 11:59 pm</b></li>
<li><i>Approximately 30% of total grade</i></li>
<li>Submit to <a href="https://www.gradescope.com/"><b>Gradescope</b></a> <i>Submission Not Yet Open</i></li>
<li>You may work in groups of 2 and submit one assignment per group.</li>
</ul>

<div id="outline-container-orgb486b14" class="outline-4">
<h4 id="orgb486b14">CODE DISTRIBUTION: <a href="a2-code.zip">a2-code.zip</a></h4>
</div>

<div id="outline-container-orgc545a04" class="outline-4">
<h4 id="orgc545a04">CHANGELOG: Empty</h4>
</div>

<div id="outline-container-org9106816" class="outline-4">
<h4 id="org9106816"></h4>
<div class="outline-text-4" id="text-org9106816">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org308e067">1. Overview</a></li>
<li><a href="#org5e58bdf">2. Download Code and Setup</a></li>
<li><a href="#org8f67565">3. <code>A2-WRITEUP.txt</code> Writeup File</a></li>
<li><a href="#orgcd83d73">4. <code>mpi_hello.c</code>: A Sample MPI Program</a></li>
<li><a href="#orgf6e5d57">5. <b>Problem 1</b>: Parallel Heat (25%)</a>
<ul>
<li><a href="#org1b6cb82">5.1. The Heat Problem</a></li>
<li><a href="#org2f93e33">5.2. MPI Heat</a></li>
<li><a href="#org9ccdfc5">5.3. Features of <code>heat_mpi</code></a></li>
<li><a href="#org1e42a77">5.4. Written Summary of the <code>heat_mpi</code> Results</a></li>
<li><a href="#orgbc068dc">5.5. Automated Tests for <code>heat_mpi</code></a></li>
<li><a href="#orgd266ee8">5.6. Grading Criteria for Problem 1</a></li>
</ul>
</li>
<li><a href="#orgf161110">6. Page Rank</a>
<ul>
<li><a href="#org9301fd8">6.1. Overview of Computing Pageranks</a></li>
<li><a href="#orgb889756">6.2. Sample Runs of <code>dense_pagerank_serial.c</code></a></li>
</ul>
</li>
<li><a href="#org42ab3c9">7. <b>Problem 2</b>: MPI PageRank (50%)</a>
<ul>
<li><a href="#org2c1ea15">7.1. Reading Data Files</a></li>
<li><a href="#org44dfe41">7.2. Row Partitioning Woes</a></li>
<li><a href="#org225b386">7.3. Parallelizing Column Normalization and Damping</a></li>
<li><a href="#orgbfd076f">7.4. Parallelizing the Repeated Matrix-vector Multiplication</a></li>
<li><a href="#orge89b463">7.5. Written Summary of <code>dense_pagerank_mpi</code> Results</a></li>
<li><a href="#org5f698c9">7.6. Automated Tests for <code>dense_pagerank_mpi</code></a></li>
<li><a href="#orgc92d52a">7.7. Grading Criteria for Problem 2</a></li>
</ul>
</li>
<li><a href="#org10a0ed3">8. <b>Problem 3</b>: OpenMP PageRank (25%)</a>
<ul>
<li><a href="#orgc251466">8.1. Shared Memory Implementation</a></li>
<li><a href="#org0c2eb16">8.2. Written Summary of <code>dense_pagerank_omp</code> Results</a></li>
<li><a href="#org008f8a5">8.3. Automated Tests for <code>dense_pagerank_omp</code></a></li>
<li><a href="#org87b90b4">8.4. Grading Criteria for Problem 3</a></li>
</ul>
</li>
<li><a href="#orgf1407f4">9. Optional MAKEUP Problem 4</a></li>
<li><a href="#orgcd6eae2">10. Project Submission on Gradescope</a>
<ul>
<li><a href="#org1a241b0">10.1. Submit to Gradescope</a></li>
<li><a href="#org7d71cad">10.2. Late Policies</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org308e067" class="outline-2">
<h2 id="org308e067"><span class="section-number-2">1</span> Overview</h2>
<div class="outline-text-2" id="text-1">
<p>
The assignment involves programming in MPI and OpenMP then describing
the results of running your programs with several different parameter
sets.  It is a programming assignment so dust off your C skills.  We
have to spent some class discussing issues related to the assignment
but it may be a good idea to review the lecture videos for when this
took place earlier in the semester. It will pay to start early to get
oriented as debugging parallel programs can be difficult and requires
time.
</p>

<p>
There are 3 problems to solve.
</p>
<ol class="org-ol">
<li>Parallelize the heat program from A1 using MPI</li>
<li>Parallelize a provided Pagerank algorithm using MPI</li>
<li>Parallelize a provided Pagerank algorithm using OpenMP</li>
</ol>

<p>
For all 3 problems, after finishing your code, you will need to run
some timing experiments and describe the results in a short text file.
</p>
</div>
</div>

<div id="outline-container-org5e58bdf" class="outline-2">
<h2 id="org5e58bdf"><span class="section-number-2">2</span> <a id="org1859d7e"></a> Download Code and Setup</h2>
<div class="outline-text-2" id="text-2">
<p>
Download the code pack linked at the top of the page. Unzip this which
will create a project folder. Create new files in this
folder. Ultimately you will re-zip this folder to submit it.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">File</th>
<th scope="col" class="org-left">State</th>
<th scope="col" class="org-left">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">ALL PROBLEMS</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>A2-WRITEUP.txt</code></td>
<td class="org-left">EDIT</td>
<td class="org-left">Fill in timing tables and write answers to discussion questions</td>
</tr>

<tr>
<td class="org-left"><code>Makefile</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Build file to compile all programs</td>
</tr>

<tr>
<td class="org-left"><code>testy</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Test running script</td>
</tr>

<tr>
<td class="org-left"><code>test_mpi.supp</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Suppression file to get Valgrind to hide some library errors</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 1</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>heat_mpi.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Problem 1 parallel version of heat</td>
</tr>

<tr>
<td class="org-left"><code>heat_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 1 serial version of the heat problem</td>
</tr>

<tr>
<td class="org-left"><code>heat-run-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 2 script to generate timing for heat</td>
</tr>

<tr>
<td class="org-left"><code>test_heat.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Problem 1 tests for heat program</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEMS 2/3 Support</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>densemat.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Utility functions for dense matrices used in pagerank</td>
</tr>

<tr>
<td class="org-left"><code>densemat.h</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Header for dense matrix utilities</td>
</tr>

<tr>
<td class="org-left"><code>graphs/tiny-20.txt</code></td>
<td class="org-left">Data</td>
<td class="org-left">Very small graph file for pagerank testing</td>
</tr>

<tr>
<td class="org-left"><code>graphs/notredame-100.txt</code></td>
<td class="org-left">Data</td>
<td class="org-left">Small graph file for pagerank testing</td>
</tr>

<tr>
<td class="org-left">&#x2026;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>graphs/notredame-8000.txt</code></td>
<td class="org-left">Data</td>
<td class="org-left">Large graph file for pagerank testing</td>
</tr>

<tr>
<td class="org-left"><code>hostfile-veggie-ip.txt</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Hostfile for MPI runs on CSE Labs veggie cluster</td>
</tr>

<tr>
<td class="org-left"><code>mpiopts.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Script to set <code>MPIOPTS</code> environment variable</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 2</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_mpi.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Problem 2 parallel version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 2 serial version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense-pagerank-mpi-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 2 script to generate timing for pagerank</td>
</tr>

<tr>
<td class="org-left"><code>test_pagerank_mpi.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">NOT YET AVAILABLE: Problem 2 tests for pagerank</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 3</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_omp.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Problem 3 parallel version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 3 serial version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense-pagerank-mpi-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 3 script to generate timing for pagerank</td>
</tr>

<tr>
<td class="org-left"><code>test_pagerank_omp.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">NOT YET AVAILABLE: Problem 3 tests for pagerank</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org8f67565" class="outline-2">
<h2 id="org8f67565"><span class="section-number-2">3</span> <code>A2-WRITEUP.txt</code> Writeup File</h2>
<div class="outline-text-2" id="text-3">
<p>
Below is a blank copy of the writeup document included in the code
pack. Fill in answers directly into this file as you complete your
programs and submit it as part of your upload.
</p>

<div class="org-src-container">
<pre class="src src-text">                              ____________

                               A2 WRITEUP
                              ____________





GROUP MEMBERS
-------------

  - Member 1: &lt;NAME&gt; &lt;X500&gt;
  - Member 2: &lt;NAME&gt; &lt;X500&gt;

  Up to 2 people may collaborate on this assignment. Write names/x.500
  below. If working alone, leave off Member 2.

  ONLY ONE GROUP MEMBER NEEDS TO SUBMIT TO GRADESCOPE.


Problem 1: heat_mpi
===================

heat_mpi Timing Table
~~~~~~~~~~~~~~~~~~~~~

  Fill in the following table on measuring the performance of your
  `heat_mpi' program on the Veggie cluster. Replace 00.00 entries with
  your actual run times. You can use the provided `heat-run-jobs.sh'
  script to ease this task.

  -----------------------------
                 Width         
   Procs   6400  25600  102400 
  -----------------------------
       1  00.00  00.00   00.00 
       2  00.00  00.00   00.00 
       4  00.00  00.00   00.00 
       8  00.00  00.00   00.00 
      10  00.00  00.00   00.00 
      16  00.00  00.00   00.00 
      32  00.00  00.00   00.00 
      64  00.00  00.00   00.00 
     128  00.00  00.00   00.00 
  -----------------------------


heat_mpi Discussion Questions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Analyze your table of results and answer the following questions.
  1. Did using more processors result in speedups?
  2. Describe any trends or anomalies you see in the timings and
     speculate on their causes - e.g. was there are a steady increase in
     runtimes, steady decrease, or jagged changes in timing?
  3. Try to explain how number of processors and problem size seem to
     affect runtimes/speedup in the problem. Consider what happens on an
     MPI run when the original host does not have enough processors to
     available to support running on the original machine and must start
     communicating with a networked machine mentioned in the `hostfile'.


Problem 2: dense_pagerank_mpi
=============================

dense_pagerank_mpi Timing Table
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Fill in the following table on measuring the performance of your
  `dense_pagerank_mpi' program on the Veggie cluster. Replace 00.00
  entries with your actual run times. You can use the provided
  `dense-pagerank-mpi-jobs.sh' script to ease this task.

  The columns are for the notredame-XXXX.txt graphs
  ----------------------------
                  size        
   Procs    501   8000  16000 
  ----------------------------
       1  00.00  00.00  00.00 
       2  00.00  00.00  00.00 
       4  00.00  00.00  00.00 
       8  00.00  00.00  00.00 
      10  00.00  00.00  00.00 
      16  00.00  00.00  00.00 
      32  00.00  00.00  00.00 
      64  00.00  00.00  00.00 
     128  00.00  00.00  00.00 
  ----------------------------


dense_pagerank_mpi Discussion Questions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Analyze your table of results and answer the following questions.
  1. Did using more processors result in speedups?
  2. Describe any trends or anomalies you see in the timings and
     speculate on their causes - e.g. was there are a steady increase in
     runtimes, steady decrease, or jagged changes in timing?
  3. Try to explain how number of processors and problem size seem to
     affect runtimes/speedup in the problem. Consider what happens on an
     MPI run when the original host does not have enough processors to
     available to support running on the original machine and must start
     communicating with a networked machine mentioned in the `hostfile'.


Problem 3: dense_pagerank_omp
=============================

dense_pagerank_omp Timing Table
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Fill in the following table on measuring the performance of your
  `dense_pagerank_omp' program on the Veggie cluster. Replace 00.00
  entries with your actual run times. You can use the provided
  `dense-pagerank-omp-jobs.sh' script to ease this task.

  The columns are for the notredame-XXXX.txt graphs
  ----------------------------
                  size        
   Procs    501   8000  16000 
  ----------------------------
       1  00.00  00.00  00.00 
       2  00.00  00.00  00.00 
       4  00.00  00.00  00.00 
       8  00.00  00.00  00.00 
      10  00.00  00.00  00.00 
      16  00.00  00.00  00.00 
      32  00.00  00.00  00.00 
      64  00.00  00.00  00.00 
     128  00.00  00.00  00.00 
  ----------------------------


dense_pagerank_omp Discussion Questions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Analyze your table of results and answer the following questions.
  1. Did using more processors result in speedups?
  2. Describe any trends or anomalies you see in the timings and
     speculate on their causes - e.g. was there are a steady increase in
     runtimes, steady decrease, or jagged changes in timing?
  3. Try to explain how number of processors and problem size seem to
     affect runtimes/speedup in the problem. Consider the number of
     physical cores which are on the Veggie machines (obtainable via
     `lscpu').
  4. Compare these timings to your MPI results (if available) and
     indicate whether the distributed memory or shared memory seems
     favorable according to your results.


OPTIONAL MAKEUP Problem 4
=========================

  If working on the optional MAKEUP problem, add information described
  in the assignment specification here.
</pre>
</div>
</div>
</div>

<div id="outline-container-orgcd83d73" class="outline-2">
<h2 id="orgcd83d73"><span class="section-number-2">4</span> <code>mpi_hello.c</code>: A Sample MPI Program</h2>
<div class="outline-text-2" id="text-4">
<p>
A simple sample program called <code>mpi_hello.c</code> is provided as part of
the code distribution.  This program includes a useful utility for
debugging purposes.
</p>

<ul class="org-ul">
<li><code>dprintf(fmt,...)</code> is like <code>pprintf()</code> except that it only prints if
the environment variable <code>DEBUG</code> is set as is shown in the run
below. This enables debugging messages to be printed but disabled
during normal runs.</li>
</ul>

<p>
Compiling and running the program can be done locally on any machine
with MPI installed as follows.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; . mpiopts.sh                       # set the MPIOPTS environment variable

&gt;&gt; mpirun $MPIOTS -np 4 ./mpi_hello   # run the code normally
Hello world from process 0 of 4 (host: val)
Hello from the root processor 0 of 4 (host: val)
Hello world from process 2 of 4 (host: val)
Hello world from process 1 of 4 (host: val)
Hello world from process 3 of 4 (host: val)

&gt;&gt; DEBUG=1 mpirun -np 4 ./mpi_hello  # enable debug messages for this run
Hello world from process 2 of 4 (host: val)
Hello world from process 3 of 4 (host: val)
Hello world from process 1 of 4 (host: val)
|DEBUG Proc 002 / 4 PID 1484871 Host val| Debug message from processor 2
|DEBUG Proc 003 / 4 PID 1484872 Host val| Debug message from processor 3
|DEBUG Proc 001 / 4 PID 1484870 Host val| Debug message from processor 1
Hello world from process 0 of 4 (host: val)
Hello from the root processor 0 of 4 (host: val)
|DEBUG Proc 000 / 4 PID 1484869 Host val| Debug message from processor 0
</pre>
</div>

<p>
Debug printing takes time and should be turned off when reporting
runtimes for programs. Using the shell commands below ensures that the
<code>DEBUG</code> environment variable is unset so debug printing is turned off
for further runs.
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; echo $DEBUG                  # check value of DEBUG env var
1                               # currently defined

&gt;&gt; unset DEBUG                  # unset it to remove it
&gt;&gt; echo $DEBUG                  # now has no value

&gt;&gt; mpirun -np 4 ./mpi_hello     # this run has no debug output
P 0: Hello world from process 0 of 4 (host: val)
Hello from the root processor 0 of 4 (host: val)
P 2: Hello world from process 2 of 4 (host: val)
P 3: Hello world from process 3 of 4 (host: val)
P 1: Hello world from process 1 of 4 (host: val)
</pre>
</div>

<p>
NOTE: the <code>dpprintf()</code> function is somewhat inefficient even when
debug output is turned off as it requires calls to <code>getenv()</code>. There
are more efficient alternatives to this that involve macros but that
also involves recompiling code. Since this is a learning exercise we
can tolerate some performance hits in the name of easier debugging. In
the wild you may want to consider alternative debug printing
techniques.
</p>
</div>
</div>

<div id="outline-container-orgf6e5d57" class="outline-2">
<h2 id="orgf6e5d57"><span class="section-number-2">5</span> <b>Problem 1</b>: Parallel Heat (25%)</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-org1b6cb82" class="outline-3">
<h3 id="org1b6cb82"><span class="section-number-3">5.1</span> The Heat Problem</h3>
<div class="outline-text-3" id="text-5-1">
<p>
A slightly modified version of the heat propagation simulation from
HW1 and in-class discussion is in the code pack and called
<code>heat_serial.c</code>. This program can be compiled and run with the
provided <code>Makefile</code> as follows.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make heat_serial             # build program
gcc -g -Wall -o heat_serial heat_serial.c

&gt;&gt; ./heat_serial                # run with no args to show help info
usage: ./heat_serial max_time width print
  max_time: int
  width: int
  print: 1 print output, 0 no printing

&gt;&gt; ./heat_serial 10 8 1         # run for 10 timesteps with 8 "elements"
   |     0     1     2     3     4     5     6     7 
---+-------------------------------------------------
  0|  20.0  50.0  50.0  50.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  50.0  50.0  50.0  30.0  10.0 
  2|  20.0  35.0  42.5  50.0  50.0  40.0  30.0  10.0 
  3|  20.0  31.2  42.5  46.2  45.0  40.0  25.0  10.0 
  4|  20.0  31.2  38.8  43.8  43.1  35.0  25.0  10.0 
  5|  20.0  29.4  37.5  40.9  39.4  34.1  22.5  10.0 
  6|  20.0  28.8  35.2  38.4  37.5  30.9  22.0  10.0 
  7|  20.0  27.6  33.6  36.3  34.7  29.8  20.5  10.0 
  8|  20.0  26.8  32.0  34.1  33.0  27.6  19.9  10.0 
  9|  20.0  26.0  30.5  32.5  30.9  26.5  18.8  10.0 

&gt;&gt; ./heat_serial 10 8 0         # same run but don't print output, useful for timing as output takes a while

&gt;&gt; ./heat_serial 12 5 1         # run for 12 timesteps with 5 columns / elements
   |     0     1     2     3     4 
---+-------------------------------
  0|  20.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  30.0  10.0 
  2|  20.0  35.0  32.5  30.0  10.0 
  3|  20.0  26.2  32.5  21.2  10.0 
  4|  20.0  26.2  23.8  21.2  10.0 
  5|  20.0  21.9  23.8  16.9  10.0 
  6|  20.0  21.9  19.4  16.9  10.0 
  7|  20.0  19.7  19.4  14.7  10.0 
  8|  20.0  19.7  17.2  14.7  10.0 
  9|  20.0  18.6  17.2  13.6  10.0 
 10|  20.0  18.6  16.1  13.6  10.0 
 11|  20.0  18.0  16.1  13.0  10.0 
</pre>
</div>
</div>
</div>

<div id="outline-container-org2f93e33" class="outline-3">
<h3 id="org2f93e33"><span class="section-number-3">5.2</span> MPI Heat</h3>
<div class="outline-text-3" id="text-5-2">
<p>
The central task of this problem is to create an MPI version of this
program named <code>heat_mpi</code> which performs the same task but uses MPI
calls to perform the heat calculations on distributed memory
machines. Once completed, this program can be run as follows.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make heat_mpi                               # build MPI version of heat program
mpicc -g -Wall -o heat_mpi heat_mpi.c

&gt;&gt; source mpiopts.sh                           # set the MPIOPTS env variable, used to suppress warnings

&gt;&gt; mpirun $MPIOPTS -np 2 ./heat_mpi 10 8 1     # run using 2 procs, 10 steps, 8 elements = 4 per proc
   |     0     1     2     3     4     5     6     7 
---+-------------------------------------------------
  0|  20.0  50.0  50.0  50.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  50.0  50.0  50.0  30.0  10.0 
  2|  20.0  35.0  42.5  50.0  50.0  40.0  30.0  10.0 
  3|  20.0  31.2  42.5  46.2  45.0  40.0  25.0  10.0 
  4|  20.0  31.2  38.8  43.8  43.1  35.0  25.0  10.0 
  5|  20.0  29.4  37.5  40.9  39.4  34.1  22.5  10.0 
  6|  20.0  28.8  35.2  38.4  37.5  30.9  22.0  10.0 
  7|  20.0  27.6  33.6  36.3  34.7  29.8  20.5  10.0 
  8|  20.0  26.8  32.0  34.1  33.0  27.6  19.9  10.0 
  9|  20.0  26.0  30.5  32.5  30.9  26.5  18.8  10.0 

&gt;&gt; mpirun $MPIOPTS -np 4 ./heat_mpi 6 12 1     # run using 4 procs, 6 steps, 12 elements = 3 per proc 
   |     0     1     2     3     4     5     6     7     8     9    10    11 
---+-------------------------------------------------------------------------
  0|  20.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  30.0  10.0 
  2|  20.0  35.0  42.5  50.0  50.0  50.0  50.0  50.0  50.0  40.0  30.0  10.0 
  3|  20.0  31.2  42.5  46.2  50.0  50.0  50.0  50.0  45.0  40.0  25.0  10.0 
  4|  20.0  31.2  38.8  46.2  48.1  50.0  50.0  47.5  45.0  35.0  25.0  10.0 
  5|  20.0  29.4  38.8  43.4  48.1  49.1  48.8  47.5  41.2  35.0  22.5  10.0 

&gt;&gt; time mpirun $MPIOPTS -np 4 ./heat_mpi 6 12 0 # same as above but suppress output and time the run
real	0m0.168s    # wall clock time to report for the run
user	0m0.102s
sys	0m0.073s
</pre>
</div>
</div>
</div>


<div id="outline-container-org9ccdfc5" class="outline-3">
<h3 id="org9ccdfc5"><span class="section-number-3">5.3</span> Features of <code>heat_mpi</code></h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>Name your program <code>heat_mpi.c</code> to be compatible with the provided
<code>Makefile</code>. It has a target to build both <code>heat_serial</code> and
<code>heat_mpi</code> if you name the source file <code>heat_mpi.c</code>.</li>
<li><p>
The serial version of the program provided accepts 3 command line arguments:
</p>
<ol class="org-ol">
<li>Number of time steps (rows in output)</li>
<li>Width of the rod in elements (columns of output)</li>
<li>1 or 0 to indicate whether final output should be printed or suppressed.</li>
</ol>
<p>
The MPI version should allow for the same arguments so that runs
like the following will work.
</p>
<div class="org-src-container">
<pre class="src src-sh">  &gt;&gt; mpirun $MPIOPTS -np 4 ./mpi_heat 10 40 1   # 4 procs, 10 timesteps, width 40, show output 
  ...                                           # output for the run

  &gt;&gt; mpirun $MPIOPTS -np 4 ./mpi_heat 10 40 0   # same but no output
  &gt;&gt; 
</pre>
</div></li>
<li><p>
There is a small script called <code>mpiopts.sh</code> which can set options
for MPI runs to suppress unnecessary warning messages. While
experimenting with your programs in a shell, you can source this
script via the following.
</p>
<div class="org-src-container">
<pre class="src src-sh">  &gt;&gt; source mpiopts.sh            # sets variable MPIOPTS
  
  &gt;&gt; echo $MPIOPTS                # show value of MPIOPTS
  --mca opal_warn_on_missing_libcuda 0
  
  &gt;&gt; . mpiopts.sh                 # same as using "source" to execute script in current shell
</pre>
</div></li>
<li>Divide the problem data so that each processor owns only a portion
of the columns of the heat matrix as discussed in class.</li>
<li>Utilize send and receives or the combined <code>MPI_Sendrecv</code> to allow
processors to communicate with neighbors.</li>
<li>Utilize a collective communication operation at the end of the
computation to gather all results on Processor 0 and have it print
out the entire results matrix if command line args indicate this is
necessary.</li>
<li>Verify that the output of your MPI version is identical to the
output of the serial version which is provided. There are a series
of automated tests that help with this which are described later.</li>
<li>To be compatible with the automated tests, <code>heat_mpi</code> must produce
an exit code of 0; e.g. <code>return 0</code> at the end of <code>main()</code> as is done
in <code>heat_serial.c</code>.</li>
<li><p>
Your MPI version is only required to work correctly in the following
situations:
</p>
<ul class="org-ul">
<li>The width of the rod in elements is evenly divisible by the number
of processors being run.</li>
<li>The width of the rod is at least three times the number of
processors so that each processor would have at least 3 columns
associated with it.</li>
</ul>
<p>
That means the following configurations should work or fail as
indicated.
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">#Procs</th>
<th scope="col" class="org-right">Width</th>
<th scope="col" class="org-left">Works?</th>
<th scope="col" class="org-left">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-left">no</td>
<td class="org-left">not enough cols</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">2</td>
<td class="org-left">no</td>
<td class="org-left">not enough cols</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">3</td>
<td class="org-left">yes</td>
<td class="org-left">take special care for 1 proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">4</td>
<td class="org-left">no</td>
<td class="org-left">only 1 column per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">8</td>
<td class="org-left">no</td>
<td class="org-left">only 2 columns per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">12</td>
<td class="org-left">yes</td>
<td class="org-left">at least 3 cols per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">16</td>
<td class="org-left">yes</td>
<td class="org-left">at least 3 cols per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">15</td>
<td class="org-left">no</td>
<td class="org-left">uneven cols</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-right">9</td>
<td class="org-left">yes</td>
<td class="org-left">3 cols per proc, evenly divisible</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">40</td>
<td class="org-left">yes</td>
<td class="org-left">evenly divisible, &gt;= 3 cols per proc</td>
</tr>
</tbody>
</table>
<p>
Runs that are marked with "no" in the "Works?" column will not be
tested so are free to do anything (segfault, work correctly, print
an error and exit immediately, etc.).
</p></li>
</ul>
</div>
</div>

<div id="outline-container-org1e42a77" class="outline-3">
<h3 id="org1e42a77"><span class="section-number-3">5.4</span> Written Summary of the <code>heat_mpi</code> Results</h3>
<div class="outline-text-3" id="text-5-4">
<p>
Included with the project code is the file <code>A2-WRITEUP.txt</code> which has
a timing table to fill in and a few discussion questions which should
be answered.
</p>

<p>
<b>Time your runs on the Veggie Cluster</b>. You can SSH into any of the
following machines to do the timing.
</p>
<div class="org-src-container">
<pre class="src src-sh">csel-broccoli.cselabs.umn.edu
csel-carrot.cselabs.umn.edu
csel-potato.cselabs.umn.edu
csel-radish.cselabs.umn.edu
csel-spinach.cselabs.umn.edu
</pre>
</div>

<p>
Gathering data for the timing table is eased via the provided
<code>heat-run-jobs.sh</code> program which will run jobs with each of the
parameters in the timing table listed. A log file is created with
output and times for each of the jobs. One can quickly extract the
timings for each job with the <code>grep</code> command.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ./heat-run-jobs.sh
Output stored in the file 'heat-timings.Fri_19_Nov_2021_04:30:13_PM_CST.log'
mpirun  --mca opal_warn_on_missing_libcuda 0  -np 1 ./heat_mpi 500 6400 0
mpirun  --mca opal_warn_on_missing_libcuda 0  -np 2 ./heat_mpi 500 6400 0
mpirun  --mca opal_warn_on_missing_libcuda 0  -np 4 ./heat_mpi 500 6400 0
...
Output stored in the file 'heat-timings.Fri_19_Nov_2021_04:30:13_PM_CST.log'

&gt;&gt; grep runtime heat-timings.Fri_19_Nov_2021_04:30:13_PM_CST.log
runtime: procs 1 width 6400 realtime 1.234
runtime: procs 2 width 6400 realtime 1.234
runtime: procs 4 width 6400 realtime 1.234
runtime: procs 8 width 6400 realtime 1.234
runtime: procs 10 width 6400 realtime 1.234
runtime: procs 16 width 6400 realtime 1.234
runtime: procs 32 width 6400 realtime 1.234
runtime: procs 64 width 6400 realtime 1.234
runtime: procs 128 width 6400 realtime 1.234
runtime: procs 1 width 12800 realtime 1.234
runtime: procs 2 width 12800 realtime 1.234
runtime: procs 4 width 12800 realtime 1.234
...
</pre>
</div>
<p>
The times above are intentionally listed all as <code>1.234</code> to prevent
biasing your own investigations.
</p>
</div>
</div>

<div id="outline-container-orgbc068dc" class="outline-3">
<h3 id="orgbc068dc"><span class="section-number-3">5.5</span> Automated Tests for <code>heat_mpi</code></h3>
<div class="outline-text-3" id="text-5-5">
<p>
A battery of automated tests are provided to evaluate whether
<code>heat_mpi</code> is producing correct results on some small examples. These
are present in the file <code>test_heat.org</code> and are run via the <code>testy</code>
script.  This can be done manually or via <code>make test-prob1</code>. Compliant
programs will give results that look like the following.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; unset DEBUG                  # enusre that DEBUG output is disabled

&gt;&gt; make test-prob1              # build prob1 program and run tests
mpicc -g -Wall -o heat_mpi heat_mpi.c
./testy test_heat.org
============================================================
== testy test_heat.org
== Running 10 / 10 tests
1)  Procs=1 Width=20           : ok
2)  Procs=1 Width=20 Valgrind  : ok
3)  Procs=2 Width=20           : ok
4)  Procs=2 Width=20 Valgrind  : ok
5)  Procs=2 Width=20 No output : ok
6)  Procs=2 Width=6            : ok
7)  Procs=2 Width=6 Valgrind   : ok
8)  Procs=4 Width=20           : ok
9)  Procs=4 Width=20 Valgrind  : ok
10) Procs=4 Steps=30 Width=40  : ok
============================================================
RESULTS: 10 / 10 tests passed
</pre>
</div>

<p>
Failed tests will provide a results file with information that can be
studied to gain insight into detected problems with the programs. 
</p>

<p>
Tests are limited to 4 processors max. Some tests run codes under
Valgrind to detect memory problems and help diagnose segmentation
faults.
</p>
</div>
</div>

<div id="outline-container-orgd266ee8" class="outline-3 grading 25">
<h3 id="orgd266ee8"><span class="section-number-3">5.6</span> <a id="org7bd468a"></a> Grading Criteria for Problem 1&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="25">25</span></span></h3>
<div class="outline-text-3" id="text-5-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Code compiles via <code>make heat_mpi</code> and passes automated tests via <code>make test-prob1</code></td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Cleanly written code with good documentation according to a Manual Inspection</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes timings table described above</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes answers to discussion questions written above.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-orgf161110" class="outline-2">
<h2 id="orgf161110"><span class="section-number-2">6</span> Page Rank</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org9301fd8" class="outline-3">
<h3 id="org9301fd8"><span class="section-number-3">6.1</span> Overview of Computing Pageranks</h3>
<div class="outline-text-3" id="text-6-1">
<p>
A key to Google's early success was its ability of its search engine
to identify web pages which seemed important to user search queries.
A key component of their engine was and remains an importance metric
metric called <a href="https://en.wikipedia.org/wiki/PageRank">Pagerank</a>, so named due to its ranking a web page and the
author of the algorithm is Larry Page (history is has a splendid sense
of irony).  The pagerank has a beautiful theory behind it which
involves modeling web users as random walkers through hyperlinked
pages. On arriving at a page, a user randomly selects a link and
visits it. This process is repeated on the next page, and the next
page, and so forth. With a small probability, a user may randomly jump
to some arbitrary other page which is not linked to the present one.
According to this formalism, pagerank represents the probability of
finding a user on a given page at a particular moment in time.  A page
with many incoming links to it has a higher probability of being
visited as many other pages have "voted" for its importance.  A page
with many outgoing links contributes little to importance of any
linked pages: its votes are spread very thin.  This rough sort of
voting turned out to be a good measure of the importance of page, at
least in the early 2000s before <a href="https://en.wikipedia.org/wiki/Google_bomb">web denizens learned to manipulate the
algorithm</a>.
</p>

<p>
It turns out that if the network of links web pages is represented as
a certain matrix, the page ranks are identical to a particular
eigenvector of that matrix.  There are several interesting facets to
this relationship for the mathematically inclined and good reading on
the subject comes from <a href="http://snap.stanford.edu/class/cs224w-readings/berkhin05pagerank.pdf">a survey by Bherkin</a>. The bottom line is that
any algorithms for computing an eigenvector of a matrix can be used to
compute page ranks.  A classical iterative technique to compute
eigenvectors is the <a href="https://en.wikipedia.org/wiki/Power_iteration">Power Method</a> which involves repeatedly multiplying
a vector by a matrix. Matrix-vector multiplication is a ripe operation
for parallelization and your primary task will be to parallelize this
process for the pagerank computation.
</p>

<p>
A code is provided called <code>dense_pagerank_serial.c</code> which performs pagerank
serial computations.  In high-level terms the computation breaks down
as follows.
</p>
<ol class="org-ol">
<li><b>Load data</b> for a matrix of web page links (<b>link matrix</b>).  Each
page is numbered 0 to <code>N-1</code> where <code>N</code> is the total number of pages.
The file format is simply pairs of numbers of one page pointing to
another one.  Loading the file involves allocating memory for the
entire matrix, zeroing each entry, then filling a 1 into each
row/col entry indicated by the file.</li>
<li><b>Normalize columns</b> by summing each column in the matrix, then
dividing each entry in a column by the sum of the column.</li>
<li><b>Apply a damping factor</b> which allows random warping from one page
to another.  The math on this is a little funky, but the intent is
to make each nonzero entry in the matrix a little smaller and each
zero entry nonzero so there is a chance of jumping to an arbitrary
page.  See the code for the specific math involved with the
update. A typical damping factor is 0.85: 85% chance of visiting a
link on the page and 15% change of jumping an arbitrary unlinked
page. This modifies the initial Link matrix once at the beginning
of the pagerank calculation.</li>
<li><b>Initialize pageranks</b> to be equal for each page and so that the
pageranks sum to 1.  If there are 10 pages, each page initially has
a pagerank of 0.1; with 100 pages each has 0.01.  Only the relative
size between ranks is important.</li>
<li><b>Multiply the link matrix by the pageranks</b> according to the
standard matrix-vector multiplication algorithm.  Store the results
in a second array of numbers.  This second array of numbers is now
the <b>new pageranks</b>.  Assign this back to the array of old
pageranks after checking for convergence.</li>
<li><b>Repeat step 5</b> of creating new pageranks by multiplying the link
matrix by the old pageranks.  Continue repeating this until there
is very little change between new and old pageranks.  At this
point, the solution has converged.</li>
</ol>

<p>
This algorithm is a good example of iterative algorithms: it is not
known ahead of time how many steps will be required to converge but
steady progress should be made as indicated by the old and new
pagerank vectors being closer and closer together.
</p>

<p>
Note that due to the columns of the link matrix and the vector of
pageranks being positive and summing to 1, the results of their
multiplication should also sum to 1 (e.g. the new pageranks also sum
to 1).  The code presently reports the <b>norm</b> of the vector as this
sum and it should remain 1 throughout the computation.
</p>

<p>
It should be mentioned that the provided code is a <b>dense</b> version of
the pagerank: every element of the link matrix has memory allocated to
it.  Unsurprisingly, a production version of the code would use
<b>sparse</b> matrices instead where the many zero entries of the matrix
are represented implicitly to save a tremendous amount of memory.
While the dense algorithm is easier to parallelize than the sparse,
the dense version is woefully inappropriate for the enormous size of
Google-scale pagerank computations involving 30,000,000,000,000+ web
pages. It is a computation that necessitates parallelism at a
sickening scale but is reasonably approximated by the present code.
</p>

<p>
Take some time to examine the code provided carefully. 
</p>
</div>
</div>

<div id="outline-container-orgb889756" class="outline-3">
<h3 id="orgb889756"><span class="section-number-3">6.2</span> Sample Runs of <code>dense_pagerank_serial.c</code></h3>
<div class="outline-text-3" id="text-6-2">
<p>
Part of the code distribution includes some graph files which you can
use for experimentation and timing analysis of your code.  Each graph
is named after its size and content.  The <code>notredame</code> graphs are
derived from a real dataset of web sites in the Notre Dame domain. The
full set is <a href="http://snap.stanford.edu/data/#web">available here</a> though will require a bit of processing to
be used with this code and is extremely large for a dense pagerank
calculation.  
</p>

<p>
Start by experimenting with the small graphs like <code>tiny-20.txt</code> which
has only 20 nodes in it and 200 links between pages.
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ls graphs/*.txt
graphs/notredame-100.txt    graphs/notredame-2000.txt  graphs/notredame-8000.txt
graphs/notredame-16000.txt  graphs/notredame-501.txt   graphs/tiny-20.txt

&gt;&gt; make dense_pagerank_serial 
gcc -g -Wall -o dense_pagerank_serial dense_pagerank_serial.c densemat.c -lm

&gt;&gt; dense_pagerank_serial graphs/tiny-20.txt 0.85 
Loaded graphs/tiny-20.txt: 20 rows, 200 nonzeros
Beginning Computation

ITER     DIFF     NORM
  1: 1.78e-01 1.00e+00
  2: 3.85e-02 1.00e+00
  3: 7.27e-03 1.00e+00
  4: 1.32e-03 1.00e+00
  5: 2.12e-04 1.00e+00
CONVERGED

PAGE RANKS
0.04779640
0.04147775
0.04912589
0.03965692
0.05845908
0.04394957
0.02513647
0.04369224
0.05522195
0.07147504
0.05889092
0.06569723
0.05264261
0.03913282
0.05423814
0.05833793
0.04308603
0.06827848
0.03697897
0.04672553
</pre>
</div>

<p>
The progress at each iteration is reported: the <code>DIFF</code> column should
get progressively smaller while the <code>NORM</code> column should remain 1
throughout.  After convergence, the pageranks of the 20 pages are
printed.
</p>

<p>
The largest graph you should work with is <code>notredame-8000.txt</code>
which has 8000 web sites involved in it leading to an 8000 by 8000
link matrix.  Running this through the serial code looks like the
following.  Note that the output will be long (8000+ lines) so it is
put into the file <code>output.txt</code> and examined using the <code>head</code> command
to display the first few lines.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ls graphs/*.txt
graphs/notredame-100.txt    graphs/notredame-2000.txt  graphs/notredame-8000.txt
graphs/notredame-16000.txt  graphs/notredame-501.txt   graphs/tiny-20.txt

&gt;&gt; dense_pagerank_serial graphs/notredame-8000.txt 0.85 &gt; output.txt
&gt;&gt; head -50 output.txt
Loaded graphs/notredame-8000.txt: 8000 rows, 27147 nonzeros
Beginning Computation

ITER     DIFF     NORM
  1: 1.26e+00 1.00e+00
  2: 7.92e-01 1.00e+00
  3: 4.24e-01 1.00e+00
  4: 2.48e-01 1.00e+00
  5: 1.50e-01 1.00e+00
  6: 9.45e-02 1.00e+00
  7: 6.23e-02 1.00e+00
  8: 4.11e-02 1.00e+00
  9: 2.73e-02 1.00e+00
 10: 1.91e-02 1.00e+00
 11: 1.31e-02 1.00e+00
 12: 9.24e-03 1.00e+00
 13: 6.74e-03 1.00e+00
 14: 4.91e-03 1.00e+00
 15: 3.75e-03 1.00e+00
 16: 2.81e-03 1.00e+00
 17: 2.16e-03 1.00e+00
 18: 1.64e-03 1.00e+00
 19: 1.27e-03 1.00e+00
 20: 9.79e-04 1.00e+00
CONVERGED

PAGE RANKS
0.00227804
0.00044506
0.00001875
0.00051994
0.00156742
0.00015092
0.00087703
0.00111392
0.00123884
0.00081005
0.00252026
0.00359624
0.00007052
...
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org42ab3c9" class="outline-2">
<h2 id="org42ab3c9"><span class="section-number-2">7</span> <b>Problem 2</b>: MPI PageRank (50%)</h2>
<div class="outline-text-2" id="text-7">
<p>
Parallelize the provided <code>dense_pagerank_serial.c</code> code for
distributed systems. Call your code <code>dense_pagerank_mpi.c</code> as this is
the convention that is supported by provided <code>Makefile</code>.
</p>
</div>

<div id="outline-container-org2c1ea15" class="outline-3">
<h3 id="org2c1ea15"><span class="section-number-3">7.1</span> Reading Data Files</h3>
<div class="outline-text-3" id="text-7-1">
<p>
The program starts with reading input from a file which should be done
only on the root processor.  After reading the whole matrix into the
root processor, send chunks of the matrix to each processor for
the main part of the algorithm.
</p>

<p>
The serial code uses a <code>densemat_t</code> structure to store the matrix.
This structure uses a trick.
</p>
<ul class="org-ul">
<li>All elements are stored in a linear array called <code>all</code>.  This allows
linear index access via <code>mat-&gt;all[i]</code></li>
<li>An array of pointers called <code>data</code> points to the beginning of each
row in the matrix. This allows row/col access via <code>mat-&gt;data[r][c]</code>.</li>
<li>As a consequence of the linear array, sequential rows are stored in
adjacent memory. In a 10 by 10 matrix, rows 0, 1, and 2 are stored
in elements 0-29 of <code>mat-&gt;all</code>.  This makes it possible to send
multiple adjacent rows with single communications.</li>
</ul>
</div>
</div>

<div id="outline-container-org44dfe41" class="outline-3">
<h3 id="org44dfe41"><span class="section-number-3">7.2</span> Row Partitioning Woes</h3>
<div class="outline-text-3" id="text-7-2">
<p>
The main source of parallelism is obtained by dividing up the link
matrix so that each processor owns a collection of whole rows.  This
is effective as matrix vector multiplication relies on multiplying a
whole row by a column vector (the pageranks in this case).  
</p>

<p>
<b>Do not assume</b> that the number of rows in the link matrix is evenly
divisible by the number of processors.  Make your code more flexible
than that.  This, unfortunately, means dealing with some minutia as
not every processor will send or receive the same number of elements.
As a suggested approach, do the following
</p>
<ul class="org-ul">
<li>First, assume the number of rows is evenly divisible by the number
of processors and use simple MPI calls like <code>MPI_Scatter</code> and
<code>MPI_Allgather</code> which assume every processor will receive the same
number of elements.  Make sure that this version works on some of
the input graphs for numbers of processors that evenly divide the
size.</li>
<li>When you are confident in your code above, make a backup copy of it
for safekeeping.</li>
<li>Now take the plunge and switch to the MPI vector calls which allow
one to specify then number of elements each processor will receive:
functions like <code>MPI_Scatterv</code> and <code>MPI_Allgatherv</code> (notice the <code>v</code>
at the end) take additional parameter arrays of the counts of
elements for each processor and the offsets into storage arrays
where those elements reside.  These more complex invocation may seem
tedious, but all that is really required is to set up arrays
indicating the counts elements on each processor and pass those in.
Establish these arrays near the beginning of the program and use
them throughout.</li>
</ul>
</div>
</div>

<div id="outline-container-org225b386" class="outline-3">
<h3 id="org225b386"><span class="section-number-3">7.3</span> Parallelizing Column Normalization and Damping</h3>
<div class="outline-text-3" id="text-7-3">
<p>
It is suggested that you initially let the root processor read the
whole matrix, normalize the rows, apply the damping factor, then
scatter the matrix rows to each processor.  That way the serial code
can be used to ensure normalization and damping is correct.
</p>

<p>
Later, revisit the column normalization and damping to parallelize
it. 
</p>
<ul class="org-ul">
<li>Scatter the unnormalized link matrix rows to each process</li>
<li>Have each process compute an array of its own column sums</li>
<li>Use a all-to-all reduction so that every processor has the sums of
all columns. Investigate a good MPI function for this all-to-all
reduction and potentially use the <code>MPI_IN_PLACE</code> constant to save
yourself some allocations of buffers (the manual pages for relevant
MPI functions describe this option).</li>
<li>Have each processor divide each of its elements by the appropriate
column sum.</li>
<li>Have each processor apply the damping factor adjustment to each of
its elements.</li>
</ul>
</div>
</div>

<div id="outline-container-orgbfd076f" class="outline-3">
<h3 id="orgbfd076f"><span class="section-number-3">7.4</span> Parallelizing the Repeated Matrix-vector Multiplication</h3>
<div class="outline-text-3" id="text-7-4">
<p>
The main computation loop involves repeatedly multiplying the link
matrix by the vector or pageranks.  In the parallel version, each
processor has some whole rows of the link matrix. Note the
consequences of this decomposition.
</p>
<ul class="org-ul">
<li>Each processor has some link matrix rows but must have the whole
vector of old pageranks to do the multiplication</li>
<li>After completing the multiplication, each processor will contain
only part of the new pagerank vector and must communicate its
portion of to all other processors for the next multiplication to
occur.</li>
<li>After each multiplication, each processor must also share how much
its new pageranks differ from the equivalent portion of the old
pagerank vector so that all processors can determine if the
algorithm has converged.</li>
</ul>
<p>
This will involve several collective communication operations at each
iteration to share.
</p>
</div>
</div>

<div id="outline-container-orge89b463" class="outline-3">
<h3 id="orge89b463"><span class="section-number-3">7.5</span> Written Summary of <code>dense_pagerank_mpi</code> Results</h3>
<div class="outline-text-3" id="text-7-5">
<p>
Similar to the first problem, fill in the timing table in
<code>A2-WRITEUP.txt</code> associated with this problem and answer the questions
contained in that section.
</p>

<p>
Perform your timing on the Veggie Cluster. To speed up your filling in
the timing table, use the provided script <code>dense-pagerank-mpi-jobs.sh</code>
which will run jobs for the parameters in the timing table. One can
<code>grep</code> for the times amid the log file that is created as shown below.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ./dense-pagerank-mpi-jobs.sh                                                                                                                                
Output stored in the file 'dense-pagerank-mpi-timings.Fri_19_Nov_2021_04:16:25_PM_CST.log'                                                                                                    
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 1 ./dense_pagerank_mpi graphs/notredame-501.txt 0.85                                                        
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 4 ./dense_pagerank_mpi graphs/notredame-501.txt 0.85                                                        
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 10 ./dense_pagerank_mpi graphs/notredame-501.txt 0.85
...
Output stored in the file 'dense-pagerank-mpi-timings.Fri_19_Nov_2021_04:16:25_PM_CST.log'

&gt;&gt; grep runtime dense-pagerank-mpi-timings.Fri_19_Nov_2021_04:16:25_PM_CST.log
runtime: procs 1 graph notredame-501.txt realtime 1.234
runtime: procs 4 graph notredame-501.txt realtime 1.234
runtime: procs 10 graph notredame-501.txt realtime 1.234
...
</pre>
</div>
</div>
</div>

<div id="outline-container-org5f698c9" class="outline-3">
<h3 id="org5f698c9"><span class="section-number-3">7.6</span> Automated Tests for <code>dense_pagerank_mpi</code></h3>
<div class="outline-text-3" id="text-7-6">
<p>
Automated tests will be released later.
</p>

<p>
When the tests are released, you may run them with the provided
<code>Makefile</code> via the following target:
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make test-prob2
...
</pre>
</div>
</div>
</div>
<div id="outline-container-orgc92d52a" class="outline-3 grading 50">
<h3 id="orgc92d52a"><span class="section-number-3">7.7</span> Grading Criteria for Problem 2&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="50">50</span></span></h3>
<div class="outline-text-3" id="text-7-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Code compiles via <code>make dense_pagerank_mpi</code>, honors command line parameters on integrative runs.</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Passes automated tests via <code>make test-prob2</code> which also checks for memory problems.</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Cleanly written code with good documentation according to a Manual Inspection</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Written report includes timings table described above</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Written report includes answers to discussion questions written above.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-org10a0ed3" class="outline-2">
<h2 id="org10a0ed3"><span class="section-number-2">8</span> <b>Problem 3</b>: OpenMP PageRank (25%)</h2>
<div class="outline-text-2" id="text-8">
<p>
Similar to Problem 2, in this problem create a version of
<code>dense_pagerank_serial.c</code> which is  parallelized for shared memory
systems using <b>OpenMP</b>. Call this program <code>dense_pagerank_omp.c</code> as
this will make it compatible with the provided <code>Makefile</code>.
</p>
</div>

<div id="outline-container-orgc251466" class="outline-3">
<h3 id="orgc251466"><span class="section-number-3">8.1</span> Shared Memory Implementation</h3>
<div class="outline-text-3" id="text-8-1">
<p>
It is best to start with the Serial Pagerank code and begin augmenting
loops via compiler directives.  This should prove fairly
straight-forward to do for most loops but take the following into
consideration.
</p>

<ul class="org-ul">
<li>Provide brief documentation comments for each loop that you will
parallelize</li>
<li>Pay special attention to any shared data that appears in the loops
which one must use synchronization primitives to protect. Comment
any atomic actions, critical regions, or reductions that are needed.</li>
<li>If any loops seem unworthy of parallelizing, comment on this as
well. For instance, if you are deciding to parallelize and Inner vs
and Outer loop, describe in a few lines your rationale.</li>
<li>EXCEPTION: Loops that must be serial as they produce output via
<code>printf()</code> do not need to be commented.</li>
</ul>
</div>
</div>

<div id="outline-container-org0c2eb16" class="outline-3">
<h3 id="org0c2eb16"><span class="section-number-3">8.2</span> Written Summary of <code>dense_pagerank_omp</code> Results</h3>
<div class="outline-text-3" id="text-8-2">
<p>
As before, add fill in the timing table provided in <code>A2-WRITEUP.txt</code>
in the section for Problem 3.  The script <code>dense-pagerank-omp.sh</code> is
provided to ease this. Run your experiments on the Veggie cluster.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ./dense-pagerank-omp-jobs.sh
Output stored in the file 'dense-pagerank-omp-timings.Fri_19_Nov_2021_08:44:39_PM_CST.log'
OMP_NUM_THREADS=1 ./dense_pagerank_omp graphs/notredame-501.txt 0.85
OMP_NUM_THREADS=4 ./dense_pagerank_omp graphs/notredame-501.txt 0.85
OMP_NUM_THREADS=10 ./dense_pagerank_omp graphs/notredame-501.txt 0.85
...
Output stored in the file 'dense-pagerank-omp-timings.Fri_19_Nov_2021_08:44:39_PM_CST.log'

&gt;&gt; grep runtime dense-pagerank-omp-timings.Fri_19_Nov_2021_08:44:39_PM_CST.log
runtime: procs 1 graph notredame-501.txt realtime 1.23
runtime: procs 4 graph notredame-501.txt realtime 1.23
runtime: procs 10 graph notredame-501.txt realtime 1.23
...
</pre>
</div>
</div>
</div>

<div id="outline-container-org008f8a5" class="outline-3">
<h3 id="org008f8a5"><span class="section-number-3">8.3</span> Automated Tests for <code>dense_pagerank_omp</code></h3>
<div class="outline-text-3" id="text-8-3">
<p>
Automated tests will be released later.
</p>

<p>
When the tests are released, you may run them with the provided
<code>Makefile</code> via the following target:
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make test-prob3
...
</pre>
</div>
</div>
</div>

<div id="outline-container-org87b90b4" class="outline-3 grading 25">
<h3 id="org87b90b4"><span class="section-number-3">8.4</span> Grading Criteria for Problem 3&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="25">25</span></span></h3>
<div class="outline-text-3" id="text-8-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Code compiles via <code>make dense_pagerank_omp</code> and passes automated tests via <code>make test-prob3</code></td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Cleanly written code with good documentation according to a Manual Inspection</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">IMPORTANT: Loop augmented with <code>#pragma</code> directives should have comments describing why</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">any special considerations such as race conditions, reductions, inner vs outer loop</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">parallelization, or other considerations. Serial Output <code>printf()</code> loops do not need to</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">be documented in this way.</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes timings table described above</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes answers to discussion questions written above.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


<div id="outline-container-orgf1407f4" class="outline-2">
<h2 id="orgf1407f4"><span class="section-number-2">9</span> Optional MAKEUP Problem 4</h2>
<div class="outline-text-2" id="text-9">
<p>
An optional Makeup problem will be described here shortly. It is
likely to involve creating a version of <code>dense_pagerank_serial.c</code>
which uses BLAS library calls instead of the hand-coded linear algebra
and then timing the results to compare against the parallel versions. 
</p>

<p>
Additional instructions will be posted shortly.
</p>
</div>
</div>

<div id="outline-container-orgcd6eae2" class="outline-2">
<h2 id="orgcd6eae2"><span class="section-number-2">10</span> Project Submission on Gradescope</h2>
<div class="outline-text-2" id="text-10">
<p>
NOTE 1: Submission to Gradescope is not yet open; follow the
instructions in this section when it opens.
</p>

<p>
NOTE 2: The instructions below pertain to another class and some of
the pictures mention "project" and <code>p1-code</code> which in our case is
"assignment" and <code>a2-code</code>.  The instructions apply nonetheless and
boil down to:
</p>
<ol class="org-ol">
<li>Create a zip of your assignment code via <code>make zip</code></li>
<li>Upload the code to Gradescope</li>
<li>Check that the automated tests that run on Gradescope match you
expectations.</li>
<li>Add you partner to your submission. Only one partner should submit
the code.</li>
</ol>
</div>

<div id="outline-container-org1a241b0" class="outline-3">
<h3 id="org1a241b0"><span class="section-number-3">10.1</span> <a id="org461f95d"></a> Submit to Gradescope</h3>
<div class="outline-text-3" id="text-10-1">
<p>
Some of the pictures below mention 'Assignment' which is now 'Project'
and may mention some files that are not part of the current
project. The process of uploading submission is otherwise the same.
</p>

<ol class="org-ol">
<li><p>
In a terminal, change to your project code directory and type <b>make
zip</b> which will create a zip file of your code. A session should
look like this:
</p>
<div class="org-src-container">
<pre class="src src-sh">   &gt; cd Desktop/5451/a2-code      # location of assignment code

   &gt; ls 
   Makefile    dense_pagerank_mpi.c    heat_serial.c
   ...

   &gt; make zip                     # create a zip file using Makefile target
   rm -f a2-code.zip
   cd .. &amp;&amp; zip "a2-code/p1-code.zip" -r "a2-code"
     adding: a2-code/ (stored 0%)
     adding: a2-code/Makefile (deflated 68%)
     adding: a2-code/dense_pagerank_mpi.c (deflated 69%)
     adding: a2-code/test_dense_pagerank_mpi.org (deflated 71%)
     ...
   Zip created in a2-code.zip

   &gt; ls a2-code.zip
   a2-code.zip
</pre>
</div></li>
<li><p>
Log into <a href="https://www.gradescope.com/">Gradescope</a> and locate and click 'Assignment 2' which will
open up submission
</p>
<div class="org-center">

<div id="org8033805" class="figure">
<p><img src="gradescope01.png" alt="gradescope01.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
Click on the 'Drag and Drop' text which will open a file selection
dialog; locate and choose your <code>a2-code.zip</code> file
</p>
<div class="org-center">

<div id="org94ecea7" class="figure">
<p><img src="gradescope02.png" alt="gradescope02.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
This will show the contents of the Zip file and should include your
C source files along with testing files and directories. 
</p>
<div class="org-center">

<div id="orgd516240" class="figure">
<p><img src="gradescope03.png" alt="gradescope03.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
Click 'Upload' which will show progress uploading files.  It may
take a few seconds before this dialog closes to indicate that the
upload is successful. Note: there is a limit of 256 files per
upload; normal submissions are not likely to have problems with
this but you may want to make sure that nothing has gone wrong such
as infinite loops creating many files or incredibly large files. 
</p>

<p>
<b>WARNING</b>: There is a limit of 256 files per zip. Doing <code>make zip</code>
will warn if this limit is exceeded but uploading to Gradescope
will fail without any helpful messages if you upload more the 256
files in a zip. 
</p>

<div class="org-center">

<div id="orgefcca4f" class="figure">
<p><img src="gradescope04.png" alt="gradescope04.png" style="max-width:100%;" />
</p>
</div>
</div></li>

<li><p>
Once files have successfully uploaded, the Autograder will begin
running the command line tests and recording results.  These are
the same tests that are run via <code>make test</code>.   
</p>
<div class="org-center">

<div id="org9a3e62b" class="figure">
<p><img src="gradescope05.png" alt="gradescope05.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
When the tests have completed, results will be displayed
summarizing scores along with output for each batch of tests.
</p>
<div class="org-center">

<div id="org82baf5d" class="figure">
<p><img src="gradescope06.png" alt="gradescope06.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><b>Don't forget to add you partner to your submission</b> after
uploading. Only one partner needs to submit the code.</li>
</ol>
</div>
</div>

<div id="outline-container-org7d71cad" class="outline-3">
<h3 id="org7d71cad"><span class="section-number-3">10.2</span> Late Policies</h3>
<div class="outline-text-3" id="text-10-2">
<p>
You may wish to review the policy on late project submission which
will cost 1 Engagement Point per day late. <b>No projects will be
accepted more than 48 hours after the deadline.</b>
</p>

<p>
<a href="https://www-users.cs.umn.edu/~kauffman/5451/syllabus.html">https://www-users.cs.umn.edu/~kauffman/5451/syllabus.html</a>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr/> <i> Author: Chris Kauffman (<a href="mailto:kauffman@umn.edu">kauffman@umn.edu</a>) <br/> Date: 2021-11-19 Fri 22:28 <br/> </i>
</div>
</body>
</html>

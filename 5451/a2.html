<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-12-14 Tue 15:16 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>CSCI 5451 Assignment 2: Distributed and Shared Memory Programming</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Chris Kauffman" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<meta name="viewport" content="width=device-width, maximum-scale=1, minimum-scale=1" />
<style type="text/css">
@media screen {
:root {
--heading-bg-color:#e8c62e;
--heading-fg-color:#7a0019;
}
html {
font-family: serif;
text-align: justify;
}
pre.src, pre.example {
overflow-x: scroll;
}
/* Merge subtitle area with title area */
.subtitle {
text-align: center;
margin-top: -2em;
padding-top: 1em;
padding-bottom: 0.1em;
}
.title, .subtitle {
color: var(--heading-fg-color);
background-color: var(--heading-bg-color);
}
/* Section borders, left section header style */
div.outline-2, #table-of-contents {
background-color: rgb(250,250,250);
border: 0.75em solid var(--heading-bg-color);
border-top: 0em;
padding: 0em .5em .5em .5em; /* top right bottom left */
margin: 1em 0em 1em 0em; /* top right bottom left */
}
div.outline-2 > h2, #table-of-contents > h2 {
background-color: var(--heading-bg-color);
color: var(--heading-fg-color);
font-variant: small-caps;
padding: 0em 0em 0em .5em; /* top right bottom left */
margin: 0em -.5em 0em -.75em; /* top right bottom left */
text-align: left;
}
blockquote {
font-style: italic;
}
td, th {
padding-top: 2px;
padding-bottom: 2px;
}
body {
background-color: #EEE;
}
pre {
}
#content, #preamble, #postamble {
margin-left:300px;
}
.tag {
background-color: inherit; font-family: inherit;
padding: inherit; font-size: 80%; font-weight: inherit;
text-transform: uppercase;
}

.figure p { text-align: inherit; }
figure-number { font-style: italic; }
#table-of-contents {
text-align: left;
position: fixed;
left: 0;
margin: 0 auto;
padding: 0;
width: 300px;
top: 0;
height: 100%;
border: 0;
display: block;
}
#text-table-of-contents {
overflow-y: scroll;
height: 100%;
}
#text-table-of-contents ul {
padding-left: 1em;
margin-left: 0.5em;
}
#table-of-contents > h2 {
padding: 0.1em;
margin: 0;
}
/* adjustments for small screen, toc at top only */
@media (max-width: 800px) { /* landscape for iphone */
html {
-webkit-text-size-adjust: none;  /* prevent scaling of text on mobile */
}
body {
background-color: #EEE;
width:100%;
margin:0 auto;
}
#content, #preamble, #postamble {
margin-left:0;
}
#table-of-contents {
position: static;
left: inherit;
width:inherit;
height: auto;
border-top: 0em;
padding: 0em .5em .5em .5em; /* top right bottom left */
margin: 1em 0em 1em 0em; /* top right bottom left */
border: 0.75em solid #006633;
}
div.outline-2, #table-of-contents {
background-color: rgb(250,250,250);
border: 0.75em solid var(--heading-bg-color);
border-top: 0em;
padding: 0em .5em .5em .5em; /* top right bottom left */
margin: 1em 0em 1em 0em; /* top right bottom left */
}
div.outline-2 > h2, #table-of-contents > h2 {
background-color: var(--heading-bg-color);
color: var(--heading-fg-color);
font-variant: small-caps;
padding: 0em 0em 0em .5em; /* top right bottom left */
margin: 0em -.5em 0em -.75em; /* top right bottom left */
text-align: left;
}
#text-table-of-contents {
overflow-y: visible;
height: inherit;
}
#text-table-of-contents ul {
padding-left: 1em;
margin-left: 0.5em;
}
}
.linenr { font-size: xx-small; }
}

@media print {
html {
font-family: serif;
font-size: 10pt;
text-align: justify;
.linenr { font-size: xx-small; }
}
}
</style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="preamble" class="status">
<i>Last Updated: 2021-12-14 Tue 15:16</i>
</div>
<div id="content">
<h1 class="title">CSCI 5451 Assignment 2: Distributed and Shared Memory Programming</h1>
<ul class="org-ul">
<li><b>Due: Wed 12/15/2021 by 11:59 pm</b></li>
<li><i>Approximately 30% of total grade</i></li>
<li>Submit to <a href="https://www.gradescope.com/"><b>Gradescope</b></a></li>
<li>You may work in groups of 2 and submit one assignment per group.</li>
</ul>

<div id="outline-container-org134e46e" class="outline-4">
<h4 id="org134e46e">CODE DISTRIBUTION: <a href="a2-code.zip">a2-code.zip</a></h4>
</div>
<div id="outline-container-orgfcadecf" class="outline-4">
<h4 id="orgfcadecf">TESTFILE UPDATE: <a href="a2-tests-update.zip">a2-tests-update.zip</a></h4>
</div>

<div id="outline-container-org4356651" class="outline-4">
<h4 id="org4356651">PROBLEM 4 UPDATE: <a href="a2-prob4.zip">a2-prob4.zip</a></h4>
</div>


<div id="outline-container-org627e2d6" class="outline-4">
<h4 id="org627e2d6">CHANGELOG:</h4>
<div class="outline-text-4" id="text-org627e2d6">
<dl class="org-dl">
<dt>Tue Dec 14 03:13:08 PM CST 2021</dt><dd>A <a href="#org95a201f">demonstration of the commands</a> to run to set up SSH keys for MPI
runs on the veggie cluster is now available in the
specification. Most students are beyond this stage but if you are
getting stalls in your runs of the timing script for heat or
pagerank, then you may need to run the commands described in this
section.</dd>

<dt>Tue Dec  7 04:41:22 PM CST 2021</dt><dd>The Optional <a href="#org56a5250">Problem 4</a> has been posted which is worth 15% assignment
MAKEUP credit (will add to overall credit earned in the Assignment
category for the course). As promised, the problem reimplemnts
<code>dense_pagerank_serial</code> to utilize BLAS routines. See its
description for details. There are two additional files for
testing/timing which have been added to assignment codepack or can
be downloaded individually here: <a href="a2-prob4.zip">a2-prob4.zip</a>.</dd>

<dt>Sun Dec  5 10:42:40 PM CST 2021</dt><dd><p>
Several updates to files to correct for issues raised on Piazza.
</p>

<p>
Updated test files can be downloaded from the top of the spec or
directly here: <a href="a2-tests-update.zip">a2-tests-update.zip</a> 
</p>

<p>
<code>test_mpi.supp</code> has been updated to suppress Valgrind errors that
originate from the OpenMPI library and limit errors to those that
appear to come from student code. This is only (partially)
guaranteed to work on the CSEL veggie cluster and Gradescope.
</p>

<p>
Testing files have been updated and added for Problems 2 &amp; 3. This
includes <code>testy, Makefile, test_dense_pagerank_mpi.org,
  test_dense_pagerank_omp.org</code>.
</p>

<p>
The job running shell scripts have been updated to correct some
minor inconsistencies.
</p>
<ul class="org-ul">
<li><code>dense-pagerank-mpi-jobs.sh</code>: added the some proc numbers for job
runs so that all proc numbers in the timing table in
<code>A2-WRITEUP.txt</code> are run with the script.</li>

<li><code>dense-pagerank-omp-same.sh</code>: same as for
<code>dense-pagerank-mpi-jobs.sh</code>.</li>
</ul>

<p>
Submission on Gradescope is now open and should reflect the
automated test results on the Veggie cluster.
</p></dd>

<dt>Tue Nov 30 02:31:43 PM CST 2021</dt><dd><p>
A minor bug was reported in
<code>heat_serial.c</code> and has been corrected. During initial memory
allocation the wrong type was used in a <code>malloc()</code> but this has been
corrected as shown below.
</p>
<div class="org-src-container">
<pre class="src src-c"><span class="linenr">49: </span>    // Allocate memory 
<span class="linenr">50: </span>    H = malloc(sizeof(double*)*max_time); 
<span class="linenr">51: </span>    int t,p;
<span class="linenr">52: </span>    for(t=0;t&lt;max_time;t++){
<span class="linenr">53: </span>      H[t] = malloc(sizeof(double)*width); // was sizeof(double*), now fixed
<span class="linenr">54: </span>    }
</pre>
</div>
<p>
Luckily this mistake had no impact as the size of <code>double</code> and
<code>double*</code> on most 64-bit systems is the same, 8 bytes. You may wish
to correct this in your <code>heat_mpi.c</code> version of the code if you used
a similar allocation.
</p></dd>
</dl>
</div>
</div>


<div id="outline-container-org8ee88c7" class="outline-4">
<h4 id="org8ee88c7"></h4>
<div class="outline-text-4" id="text-org8ee88c7">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgcc48ba9">1. Overview</a></li>
<li><a href="#org74fa0a8">2. Download Code and Setup</a></li>
<li><a href="#orgeffd943">3. <code>A2-WRITEUP.txt</code> Writeup File</a></li>
<li><a href="#org067235e">4. <code>mpi_hello.c</code>: A Sample MPI Program</a></li>
<li><a href="#orge75d713">5. <b>Problem 1</b>: Parallel Heat (25%)</a>
<ul>
<li><a href="#org3b5ed81">5.1. The Heat Problem</a></li>
<li><a href="#orgef89c75">5.2. MPI Heat</a></li>
<li><a href="#orgdcb63c5">5.3. Features of <code>heat_mpi</code></a></li>
<li><a href="#org4274a11">5.4. Written Summary of the <code>heat_mpi</code> Results</a></li>
<li><a href="#org76d0d3d">5.5. Automated Tests for <code>heat_mpi</code></a></li>
<li><a href="#org2ee8cb4">5.6. Grading Criteria for Problem 1</a></li>
<li><a href="#orgee6ebfc">5.7. MPI Setup on CSE Labs</a></li>
</ul>
</li>
<li><a href="#org4a571f3">6. Page Rank</a>
<ul>
<li><a href="#org037f922">6.1. Overview of Computing Pageranks</a></li>
<li><a href="#org2768664">6.2. Sample Runs of <code>dense_pagerank_serial.c</code></a></li>
</ul>
</li>
<li><a href="#org8bcdfa1">7. <b>Problem 2</b>: MPI PageRank (50%)</a>
<ul>
<li><a href="#orgc7b7591">7.1. Reading Data Files</a></li>
<li><a href="#orgd871c4d">7.2. Row Partitioning Woes</a></li>
<li><a href="#org1b00484">7.3. Parallelizing Column Normalization and Damping</a></li>
<li><a href="#org4aa8fd1">7.4. Parallelizing the Repeated Matrix-vector Multiplication</a></li>
<li><a href="#orgc7f8c43">7.5. Written Summary of <code>dense_pagerank_mpi</code> Results</a></li>
<li><a href="#orgd715edd">7.6. Automated Tests for <code>dense_pagerank_mpi</code></a></li>
<li><a href="#orga402221">7.7. Grading Criteria for Problem 2</a></li>
</ul>
</li>
<li><a href="#orgeedde1a">8. <b>Problem 3</b>: OpenMP PageRank (25%)</a>
<ul>
<li><a href="#orgc2a1881">8.1. Shared Memory Implementation</a></li>
<li><a href="#org1663bdb">8.2. Written Summary of <code>dense_pagerank_omp</code> Results</a></li>
<li><a href="#orgdf71b7a">8.3. Automated Tests for <code>dense_pagerank_omp</code></a></li>
<li><a href="#orgcbc353e">8.4. Grading Criteria for Problem 3</a></li>
</ul>
</li>
<li><a href="#orgcfe96b6">9. Optional MAKEUP Problem 4 (15%)</a>
<ul>
<li><a href="#org9d8cc9d">9.1. BLAS Functions to Consider</a></li>
<li><a href="#org9f42e58">9.2. Building the Code</a></li>
<li><a href="#org4f41fc2">9.3. Testing and Timing</a></li>
<li><a href="#org24b4b60">9.4. Grading Criteria for Problem 4</a></li>
</ul>
</li>
<li><a href="#org7fce424">10. Project Submission on Gradescope</a>
<ul>
<li><a href="#orged0d582">10.1. Submit to Gradescope</a></li>
<li><a href="#orgf9d817b">10.2. Late Policies</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>


<div id="outline-container-orgcc48ba9" class="outline-2">
<h2 id="orgcc48ba9"><span class="section-number-2">1</span> Overview</h2>
<div class="outline-text-2" id="text-1">
<p>
The assignment involves programming in MPI and OpenMP then describing
the results of running your programs with several different parameter
sets.  It is a programming assignment so dust off your C skills.  We
have to spent some class discussing issues related to the assignment
but it may be a good idea to review the lecture videos for when this
took place earlier in the semester. It will pay to start early to get
oriented as debugging parallel programs can be difficult and requires
time.
</p>

<p>
There are 3 problems to solve.
</p>
<ol class="org-ol">
<li>Parallelize the heat program from A1 using MPI</li>
<li>Parallelize a provided Pagerank algorithm using MPI</li>
<li>Parallelize a provided Pagerank algorithm using OpenMP</li>
</ol>

<p>
For all 3 problems, after finishing your code, you will need to run
some timing experiments and describe the results in a short text file.
</p>
</div>
</div>

<div id="outline-container-org74fa0a8" class="outline-2">
<h2 id="org74fa0a8"><span class="section-number-2">2</span> Download Code and Setup</h2>
<div class="outline-text-2" id="text-2">
<p>
Download the code pack linked at the top of the page. Unzip this which
will create a project folder. Create new files in this
folder. Ultimately you will re-zip this folder to submit it.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">File</th>
<th scope="col" class="org-left">State</th>
<th scope="col" class="org-left">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">ALL PROBLEMS</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>A2-WRITEUP.txt</code></td>
<td class="org-left">EDIT</td>
<td class="org-left">Fill in timing tables and write answers to discussion questions</td>
</tr>

<tr>
<td class="org-left"><code>Makefile</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Build file to compile all programs</td>
</tr>

<tr>
<td class="org-left"><code>testy</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Test running script</td>
</tr>

<tr>
<td class="org-left"><code>test_mpi.supp</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Suppression file to get Valgrind to hide some library errors</td>
</tr>

<tr>
<td class="org-left"><code>mpi_hello.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Demo MPI program along with debug printing function</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 1</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>heat_mpi.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Problem 1 parallel version of heat</td>
</tr>

<tr>
<td class="org-left"><code>heat_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 1 serial version of the heat problem</td>
</tr>

<tr>
<td class="org-left"><code>heat-run-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 2 script to generate timing for heat</td>
</tr>

<tr>
<td class="org-left"><code>test_heat.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Problem 1 tests for heat program</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEMS 2/3 Support</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>densemat.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Utility functions for dense matrices used in pagerank</td>
</tr>

<tr>
<td class="org-left"><code>densemat.h</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Header for dense matrix utilities</td>
</tr>

<tr>
<td class="org-left"><code>graphs/tiny-20.txt</code></td>
<td class="org-left">Data</td>
<td class="org-left">Very small graph file for pagerank testing</td>
</tr>

<tr>
<td class="org-left"><code>graphs/notredame-100.txt</code></td>
<td class="org-left">Data</td>
<td class="org-left">Small graph file for pagerank testing</td>
</tr>

<tr>
<td class="org-left">&#x2026;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>graphs/notredame-8000.txt</code></td>
<td class="org-left">Data</td>
<td class="org-left">Large graph file for pagerank testing</td>
</tr>

<tr>
<td class="org-left"><code>hostfile-veggie-ip.txt</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Hostfile for MPI runs on CSE Labs veggie cluster</td>
</tr>

<tr>
<td class="org-left"><code>mpiopts.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Script to set <code>MPIOPTS</code> environment variable</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 2</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_mpi.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Problem 2 parallel version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 2 serial version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense-pagerank-mpi-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 2 script to generate timing for pagerank</td>
</tr>

<tr>
<td class="org-left"><code>test_pagerank_mpi.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Problem 2 tests for pagerank</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 3</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_omp.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Problem 3 parallel version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 3 serial version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense-pagerank-omp-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Problem 3 script to generate timing for pagerank</td>
</tr>

<tr>
<td class="org-left"><code>test_pagerank_omp.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Problem 3 tests for pagerank</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">PROBLEM 4</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_blas.c</code></td>
<td class="org-left">CREATE</td>
<td class="org-left">Optional Problem 4 BLAS version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense_pagerank_serial.c</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Optional Problem 4 serial version of pagerank</td>
</tr>

<tr>
<td class="org-left"><code>dense-pagerank-blas-jobs.sh</code></td>
<td class="org-left">Provided</td>
<td class="org-left">Optional Problem 4 script to generate timing for pagerank</td>
</tr>

<tr>
<td class="org-left"><code>test_pagerank_blas.org</code></td>
<td class="org-left">Testing</td>
<td class="org-left">Optional Problem 4 tests for pagerank</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgeffd943" class="outline-2">
<h2 id="orgeffd943"><span class="section-number-2">3</span> <code>A2-WRITEUP.txt</code> Writeup File</h2>
<div class="outline-text-2" id="text-3">
<p>
Below is a blank copy of the writeup document included in the code
pack. Fill in answers directly into this file as you complete your
programs and submit it as part of your upload.
</p>

<div class="org-src-container">
<pre class="src src-text">                              ____________

                               A2 WRITEUP
                              ____________





GROUP MEMBERS
-------------

  - Member 1: &lt;NAME&gt; &lt;X500&gt;
  - Member 2: &lt;NAME&gt; &lt;X500&gt;

  Up to 2 people may collaborate on this assignment. Write names/x.500
  below. If working alone, leave off Member 2.

  ONLY ONE GROUP MEMBER NEEDS TO SUBMIT TO GRADESCOPE.


Problem 1: heat_mpi
===================

heat_mpi Timing Table
~~~~~~~~~~~~~~~~~~~~~

  Fill in the following table on measuring the performance of your
  `heat_mpi' program on the Veggie cluster. Replace 00.00 entries with
  your actual run times. You can use the provided `heat-run-jobs.sh'
  script to ease this task.

  -----------------------------
                 Width         
   Procs   6400  25600  102400 
  -----------------------------
       1  00.00  00.00   00.00 
       2  00.00  00.00   00.00 
       4  00.00  00.00   00.00 
       8  00.00  00.00   00.00 
      10  00.00  00.00   00.00 
      16  00.00  00.00   00.00 
      32  00.00  00.00   00.00 
      64  00.00  00.00   00.00 
     128  00.00  00.00   00.00 
  -----------------------------


heat_mpi Discussion Questions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Analyze your table of results and answer the following questions.
  1. Did using more processors result in speedups?
  2. Describe any trends or anomalies you see in the timings and
     speculate on their causes - e.g. was there are a steady increase in
     runtimes, steady decrease, or jagged changes in timing?
  3. Try to explain how number of processors and problem size seem to
     affect runtimes/speedup in the problem. Consider what happens on an
     MPI run when the original host does not have enough processors to
     available to support running on the original machine and must start
     communicating with a networked machine mentioned in the `hostfile'.


Problem 2: dense_pagerank_mpi
=============================

dense_pagerank_mpi Timing Table
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Fill in the following table on measuring the performance of your
  `dense_pagerank_mpi' program on the Veggie cluster. Replace 00.00
  entries with your actual run times. You can use the provided
  `dense-pagerank-mpi-jobs.sh' script to ease this task.

  The columns are for the notredame-XXXX.txt graphs
  ----------------------------
                  size        
   Procs    501   8000  16000 
  ----------------------------
       1  00.00  00.00  00.00 
       2  00.00  00.00  00.00 
       4  00.00  00.00  00.00 
       8  00.00  00.00  00.00 
      10  00.00  00.00  00.00 
      16  00.00  00.00  00.00 
      32  00.00  00.00  00.00 
      64  00.00  00.00  00.00 
     128  00.00  00.00  00.00 
  ----------------------------


dense_pagerank_mpi Discussion Questions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Analyze your table of results and answer the following questions.
  1. Did using more processors result in speedups?
  2. Describe any trends or anomalies you see in the timings and
     speculate on their causes - e.g. was there are a steady increase in
     runtimes, steady decrease, or jagged changes in timing?
  3. Try to explain how number of processors and problem size seem to
     affect runtimes/speedup in the problem. Consider what happens on an
     MPI run when the original host does not have enough processors to
     available to support running on the original machine and must start
     communicating with a networked machine mentioned in the `hostfile'.


Problem 3: dense_pagerank_omp
=============================

dense_pagerank_omp Timing Table
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Fill in the following table on measuring the performance of your
  `dense_pagerank_omp' program on the Veggie cluster. Replace 00.00
  entries with your actual run times. You can use the provided
  `dense-pagerank-omp-jobs.sh' script to ease this task.

  The columns are for the notredame-XXXX.txt graphs
  ----------------------------
                  size        
   Procs    501   8000  16000 
  ----------------------------
       1  00.00  00.00  00.00 
       2  00.00  00.00  00.00 
       4  00.00  00.00  00.00 
       8  00.00  00.00  00.00 
      10  00.00  00.00  00.00 
      16  00.00  00.00  00.00 
      32  00.00  00.00  00.00 
      64  00.00  00.00  00.00 
     128  00.00  00.00  00.00 
  ----------------------------


dense_pagerank_omp Discussion Questions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Analyze your table of results and answer the following questions.
  1. Did using more processors result in speedups?
  2. Describe any trends or anomalies you see in the timings and
     speculate on their causes - e.g. was there are a steady increase in
     runtimes, steady decrease, or jagged changes in timing?
  3. Try to explain how number of processors and problem size seem to
     affect runtimes/speedup in the problem. Consider the number of
     physical cores which are on the Veggie machines (obtainable via
     `lscpu').
  4. Compare these timings to your MPI results (if available) and
     indicate whether the distributed memory or shared memory seems
     favorable according to your results.


OPTIONAL MAKEUP Problem 4
=========================

  If working on the optional MAKEUP problem, add information described
  in the assignment specification here.
</pre>
</div>
</div>
</div>

<div id="outline-container-org067235e" class="outline-2">
<h2 id="org067235e"><span class="section-number-2">4</span> <code>mpi_hello.c</code>: A Sample MPI Program</h2>
<div class="outline-text-2" id="text-4">
<p>
A simple sample program called <code>mpi_hello.c</code> is provided as part of
the code distribution.  This program includes a useful utility for
debugging purposes.
</p>

<ul class="org-ul">
<li><code>dprintf(fmt,...)</code> is like <code>pprintf()</code> except that it only prints if
the environment variable <code>DEBUG</code> is set as is shown in the run
below. This enables debugging messages to be printed but disabled
during normal runs.</li>
</ul>

<p>
Compiling and running the program can be done locally on any machine
with MPI installed as follows.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; . mpiopts.sh                       # set the MPIOPTS environment variable

&gt;&gt; mpirun $MPIOTS -np 4 ./mpi_hello   # run the code normally
Hello world from process 0 of 4 (host: val)
Hello from the root processor 0 of 4 (host: val)
Hello world from process 2 of 4 (host: val)
Hello world from process 1 of 4 (host: val)
Hello world from process 3 of 4 (host: val)

&gt;&gt; DEBUG=1 mpirun -np 4 ./mpi_hello  # enable debug messages for this run
Hello world from process 2 of 4 (host: val)
Hello world from process 3 of 4 (host: val)
Hello world from process 1 of 4 (host: val)
|DEBUG Proc 002 / 4 PID 1484871 Host val| Debug message from processor 2
|DEBUG Proc 003 / 4 PID 1484872 Host val| Debug message from processor 3
|DEBUG Proc 001 / 4 PID 1484870 Host val| Debug message from processor 1
Hello world from process 0 of 4 (host: val)
Hello from the root processor 0 of 4 (host: val)
|DEBUG Proc 000 / 4 PID 1484869 Host val| Debug message from processor 0
</pre>
</div>

<p>
Debug printing takes time and should be turned off when reporting
runtimes for programs. Using the shell commands below ensures that the
<code>DEBUG</code> environment variable is unset so debug printing is turned off
for further runs.
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; echo $DEBUG                  # check value of DEBUG env var
1                               # currently defined

&gt;&gt; unset DEBUG                  # unset it to remove it
&gt;&gt; echo $DEBUG                  # now has no value

&gt;&gt; mpirun -np 4 ./mpi_hello     # this run has no debug output
P 0: Hello world from process 0 of 4 (host: val)
Hello from the root processor 0 of 4 (host: val)
P 2: Hello world from process 2 of 4 (host: val)
P 3: Hello world from process 3 of 4 (host: val)
P 1: Hello world from process 1 of 4 (host: val)
</pre>
</div>

<p>
NOTE: the <code>dpprintf()</code> function is somewhat inefficient even when
debug output is turned off as it requires calls to <code>getenv()</code>. There
are more efficient alternatives to this that involve macros but that
also involves recompiling code. Since this is a learning exercise we
can tolerate some performance hits in the name of easier debugging. In
the wild you may want to consider alternative debug printing
techniques.
</p>
</div>
</div>

<div id="outline-container-orge75d713" class="outline-2">
<h2 id="orge75d713"><span class="section-number-2">5</span> <b>Problem 1</b>: Parallel Heat (25%)</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-org3b5ed81" class="outline-3">
<h3 id="org3b5ed81"><span class="section-number-3">5.1</span> The Heat Problem</h3>
<div class="outline-text-3" id="text-5-1">
<p>
A slightly modified version of the heat propagation simulation from
HW1 and in-class discussion is in the code pack and called
<code>heat_serial.c</code>. This program can be compiled and run with the
provided <code>Makefile</code> as follows.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make heat_serial             # build program
gcc -g -Wall -o heat_serial heat_serial.c

&gt;&gt; ./heat_serial                # run with no args to show help info
usage: ./heat_serial max_time width print
  max_time: int
  width: int
  print: 1 print output, 0 no printing

&gt;&gt; ./heat_serial 10 8 1         # run for 10 timesteps with 8 "elements"
   |     0     1     2     3     4     5     6     7 
---+-------------------------------------------------
  0|  20.0  50.0  50.0  50.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  50.0  50.0  50.0  30.0  10.0 
  2|  20.0  35.0  42.5  50.0  50.0  40.0  30.0  10.0 
  3|  20.0  31.2  42.5  46.2  45.0  40.0  25.0  10.0 
  4|  20.0  31.2  38.8  43.8  43.1  35.0  25.0  10.0 
  5|  20.0  29.4  37.5  40.9  39.4  34.1  22.5  10.0 
  6|  20.0  28.8  35.2  38.4  37.5  30.9  22.0  10.0 
  7|  20.0  27.6  33.6  36.3  34.7  29.8  20.5  10.0 
  8|  20.0  26.8  32.0  34.1  33.0  27.6  19.9  10.0 
  9|  20.0  26.0  30.5  32.5  30.9  26.5  18.8  10.0 

&gt;&gt; ./heat_serial 10 8 0         # same run but don't print output, useful for timing as output takes a while

&gt;&gt; ./heat_serial 12 5 1         # run for 12 timesteps with 5 columns / elements
   |     0     1     2     3     4 
---+-------------------------------
  0|  20.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  30.0  10.0 
  2|  20.0  35.0  32.5  30.0  10.0 
  3|  20.0  26.2  32.5  21.2  10.0 
  4|  20.0  26.2  23.8  21.2  10.0 
  5|  20.0  21.9  23.8  16.9  10.0 
  6|  20.0  21.9  19.4  16.9  10.0 
  7|  20.0  19.7  19.4  14.7  10.0 
  8|  20.0  19.7  17.2  14.7  10.0 
  9|  20.0  18.6  17.2  13.6  10.0 
 10|  20.0  18.6  16.1  13.6  10.0 
 11|  20.0  18.0  16.1  13.0  10.0 
</pre>
</div>
</div>
</div>

<div id="outline-container-orgef89c75" class="outline-3">
<h3 id="orgef89c75"><span class="section-number-3">5.2</span> MPI Heat</h3>
<div class="outline-text-3" id="text-5-2">
<p>
The central task of this problem is to create an MPI version of this
program named <code>heat_mpi</code> which performs the same task but uses MPI
calls to perform the heat calculations on distributed memory
machines. Once completed, this program can be run as follows.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make heat_mpi                               # build MPI version of heat program
mpicc -g -Wall -o heat_mpi heat_mpi.c

&gt;&gt; source mpiopts.sh                           # set the MPIOPTS env variable, used to suppress warnings

&gt;&gt; mpirun $MPIOPTS -np 2 ./heat_mpi 10 8 1     # run using 2 procs, 10 steps, 8 elements = 4 per proc
   |     0     1     2     3     4     5     6     7 
---+-------------------------------------------------
  0|  20.0  50.0  50.0  50.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  50.0  50.0  50.0  30.0  10.0 
  2|  20.0  35.0  42.5  50.0  50.0  40.0  30.0  10.0 
  3|  20.0  31.2  42.5  46.2  45.0  40.0  25.0  10.0 
  4|  20.0  31.2  38.8  43.8  43.1  35.0  25.0  10.0 
  5|  20.0  29.4  37.5  40.9  39.4  34.1  22.5  10.0 
  6|  20.0  28.8  35.2  38.4  37.5  30.9  22.0  10.0 
  7|  20.0  27.6  33.6  36.3  34.7  29.8  20.5  10.0 
  8|  20.0  26.8  32.0  34.1  33.0  27.6  19.9  10.0 
  9|  20.0  26.0  30.5  32.5  30.9  26.5  18.8  10.0 

&gt;&gt; mpirun $MPIOPTS -np 4 ./heat_mpi 6 12 1     # run using 4 procs, 6 steps, 12 elements = 3 per proc 
   |     0     1     2     3     4     5     6     7     8     9    10    11 
---+-------------------------------------------------------------------------
  0|  20.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  10.0 
  1|  20.0  35.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  50.0  30.0  10.0 
  2|  20.0  35.0  42.5  50.0  50.0  50.0  50.0  50.0  50.0  40.0  30.0  10.0 
  3|  20.0  31.2  42.5  46.2  50.0  50.0  50.0  50.0  45.0  40.0  25.0  10.0 
  4|  20.0  31.2  38.8  46.2  48.1  50.0  50.0  47.5  45.0  35.0  25.0  10.0 
  5|  20.0  29.4  38.8  43.4  48.1  49.1  48.8  47.5  41.2  35.0  22.5  10.0 

&gt;&gt; time mpirun $MPIOPTS -np 4 ./heat_mpi 6 12 0 # same as above but suppress output and time the run
real	0m0.168s    # wall clock time to report for the run
user	0m0.102s
sys	0m0.073s
</pre>
</div>
</div>
</div>


<div id="outline-container-orgdcb63c5" class="outline-3">
<h3 id="orgdcb63c5"><span class="section-number-3">5.3</span> Features of <code>heat_mpi</code></h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>Name your program <code>heat_mpi.c</code> to be compatible with the provided
<code>Makefile</code>. It has a target to build both <code>heat_serial</code> and
<code>heat_mpi</code> if you name the source file <code>heat_mpi.c</code>.</li>
<li><p>
The serial version of the program provided accepts 3 command line arguments:
</p>
<ol class="org-ol">
<li>Number of time steps (rows in output)</li>
<li>Width of the rod in elements (columns of output)</li>
<li>1 or 0 to indicate whether final output should be printed or suppressed.</li>
</ol>
<p>
The MPI version should allow for the same arguments so that runs
like the following will work.
</p>
<div class="org-src-container">
<pre class="src src-sh">  &gt;&gt; mpirun $MPIOPTS -np 4 ./mpi_heat 10 40 1   # 4 procs, 10 timesteps, width 40, show output 
  ...                                           # output for the run

  &gt;&gt; mpirun $MPIOPTS -np 4 ./mpi_heat 10 40 0   # same but no output
  &gt;&gt; 
</pre>
</div></li>
<li><p>
There is a small script called <code>mpiopts.sh</code> which can set options
for MPI runs to suppress unnecessary warning messages. While
experimenting with your programs in a shell, you can source this
script via the following.
</p>
<div class="org-src-container">
<pre class="src src-sh">  &gt;&gt; source mpiopts.sh            # sets variable MPIOPTS
  
  &gt;&gt; echo $MPIOPTS                # show value of MPIOPTS
  --mca opal_warn_on_missing_libcuda 0
  
  &gt;&gt; . mpiopts.sh                 # same as using "source" to execute script in current shell
</pre>
</div></li>
<li>Divide the problem data so that each processor owns only a portion
of the columns of the heat matrix as discussed in class.</li>
<li>Utilize send and receives or the combined <code>MPI_Sendrecv</code> to allow
processors to communicate with neighbors.</li>
<li>Utilize a collective communication operation at the end of the
computation to gather all results on Processor 0 and have it print
out the entire results matrix if command line args indicate this is
necessary.</li>
<li>Verify that the output of your MPI version is identical to the
output of the serial version which is provided. There are a series
of automated tests that help with this which are described later.</li>
<li>To be compatible with the automated tests, <code>heat_mpi</code> must produce
an exit code of 0; e.g. <code>return 0</code> at the end of <code>main()</code> as is done
in <code>heat_serial.c</code>.</li>
<li><p>
Your MPI version is only required to work correctly in the following
situations:
</p>
<ul class="org-ul">
<li>The width of the rod in elements is evenly divisible by the number
of processors being run.</li>
<li>The width of the rod is at least three times the number of
processors so that each processor would have at least 3 columns
associated with it.</li>
</ul>
<p>
That means the following configurations should work or fail as
indicated.
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">#Procs</th>
<th scope="col" class="org-right">Width</th>
<th scope="col" class="org-left">Works?</th>
<th scope="col" class="org-left">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-left">no</td>
<td class="org-left">not enough cols</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">2</td>
<td class="org-left">no</td>
<td class="org-left">not enough cols</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">3</td>
<td class="org-left">yes</td>
<td class="org-left">take special care for 1 proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">4</td>
<td class="org-left">no</td>
<td class="org-left">only 1 column per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">8</td>
<td class="org-left">no</td>
<td class="org-left">only 2 columns per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">12</td>
<td class="org-left">yes</td>
<td class="org-left">at least 3 cols per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">16</td>
<td class="org-left">yes</td>
<td class="org-left">at least 3 cols per proc</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">15</td>
<td class="org-left">no</td>
<td class="org-left">uneven cols</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-right">9</td>
<td class="org-left">yes</td>
<td class="org-left">3 cols per proc, evenly divisible</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">40</td>
<td class="org-left">yes</td>
<td class="org-left">evenly divisible, &gt;= 3 cols per proc</td>
</tr>
</tbody>
</table>
<p>
Runs that are marked with "no" in the "Works?" column will not be
tested so are free to do anything (segfault, work correctly, print
an error and exit immediately, etc.).
</p></li>
</ul>
</div>
</div>

<div id="outline-container-org4274a11" class="outline-3">
<h3 id="org4274a11"><span class="section-number-3">5.4</span> Written Summary of the <code>heat_mpi</code> Results</h3>
<div class="outline-text-3" id="text-5-4">
<p>
Included with the project code is the file <code>A2-WRITEUP.txt</code> which has
a timing table to fill in and a few discussion questions which should
be answered.
</p>

<p>
<b>Time your runs on the Veggie Cluster</b>. You can SSH into any of the
following machines to do the timing.
</p>
<div class="org-src-container">
<pre class="src src-sh">csel-broccoli.cselabs.umn.edu
csel-carrot.cselabs.umn.edu
csel-potato.cselabs.umn.edu
csel-radish.cselabs.umn.edu
csel-spinach.cselabs.umn.edu
</pre>
</div>

<p>
Gathering data for the timing table is eased via the provided
<code>heat-run-jobs.sh</code> program which will run jobs with each of the
parameters in the timing table listed. A log file is created with
output and times for each of the jobs. One can quickly extract the
timings for each job with the <code>grep</code> command.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ./heat-run-jobs.sh
Output stored in the file 'heat-timings.Fri_19_Nov_2021_04:30:13_PM_CST.log'
mpirun  --mca opal_warn_on_missing_libcuda 0  -np 1 ./heat_mpi 500 6400 0
mpirun  --mca opal_warn_on_missing_libcuda 0  -np 2 ./heat_mpi 500 6400 0
mpirun  --mca opal_warn_on_missing_libcuda 0  -np 4 ./heat_mpi 500 6400 0
...
Output stored in the file 'heat-timings.Fri_19_Nov_2021_04:30:13_PM_CST.log'

&gt;&gt; grep runtime heat-timings.Fri_19_Nov_2021_04:30:13_PM_CST.log
runtime: procs 1 width 6400 realtime 1.234
runtime: procs 2 width 6400 realtime 1.234
runtime: procs 4 width 6400 realtime 1.234
runtime: procs 8 width 6400 realtime 1.234
runtime: procs 10 width 6400 realtime 1.234
runtime: procs 16 width 6400 realtime 1.234
runtime: procs 32 width 6400 realtime 1.234
runtime: procs 64 width 6400 realtime 1.234
runtime: procs 128 width 6400 realtime 1.234
runtime: procs 1 width 12800 realtime 1.234
runtime: procs 2 width 12800 realtime 1.234
runtime: procs 4 width 12800 realtime 1.234
...
</pre>
</div>
<p>
The times above are intentionally listed all as <code>1.234</code> to prevent
biasing your own investigations.
</p>
</div>
</div>

<div id="outline-container-org76d0d3d" class="outline-3">
<h3 id="org76d0d3d"><span class="section-number-3">5.5</span> Automated Tests for <code>heat_mpi</code></h3>
<div class="outline-text-3" id="text-5-5">
<p>
A battery of automated tests are provided to evaluate whether
<code>heat_mpi</code> is producing correct results on some small examples. These
are present in the file <code>test_heat.org</code> and are run via the <code>testy</code>
script.  This can be done manually or via <code>make test-prob1</code>. Compliant
programs will give results that look like the following.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; unset DEBUG                  # enusre that DEBUG output is disabled

&gt;&gt; make test-prob1              # build prob1 program and run tests
mpicc -g -Wall -o heat_mpi heat_mpi.c
./testy test_heat.org
============================================================
== testy test_heat.org
== Running 10 / 10 tests
1)  Procs=1 Width=20           : ok
2)  Procs=1 Width=20 Valgrind  : ok
3)  Procs=2 Width=20           : ok
4)  Procs=2 Width=20 Valgrind  : ok
5)  Procs=2 Width=20 No output : ok
6)  Procs=2 Width=6            : ok
7)  Procs=2 Width=6 Valgrind   : ok
8)  Procs=4 Width=20           : ok
9)  Procs=4 Width=20 Valgrind  : ok
10) Procs=4 Steps=30 Width=40  : ok
============================================================
RESULTS: 10 / 10 tests passed
</pre>
</div>

<p>
Failed tests will provide a results file with information that can be
studied to gain insight into detected problems with the programs. 
</p>

<p>
Tests are limited to 4 processors max. Some tests run codes under
Valgrind to detect memory problems and help diagnose segmentation
faults.
</p>
</div>
</div>

<div id="outline-container-org2ee8cb4" class="outline-3 grading 25">
<h3 id="org2ee8cb4"><span class="section-number-3">5.6</span> <a id="org8d119d0"></a> Grading Criteria for Problem 1&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="25">25</span></span></h3>
<div class="outline-text-3" id="text-5-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Code compiles via <code>make heat_mpi</code> and passes automated tests via <code>make test-prob1</code></td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Cleanly written code with good documentation according to a Manual Inspection</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes timings table described above</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes answers to discussion questions written above.</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgee6ebfc" class="outline-3">
<h3 id="orgee6ebfc"><span class="section-number-3">5.7</span> <a id="org95a201f"></a> MPI Setup on CSE Labs</h3>
<div class="outline-text-3" id="text-5-7">
<p>
Log into the Veggie Cluster and use the following commands to ensure
that SSH + MPI is set up correctly for the timing scripts to run.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ssh username@csel-carrot.cselabs.umn.edu                                # log into CSE Labs machine
...
&gt;&gt; cd 5451/a2-code                                                         # change to project directory

&gt;&gt; ssh-keygen -t rsa                                                       # create a public private key pair
Generating public/private rsa key pair.
Enter file in which to save the key (/home/kauffman/.ssh/id_rsa):          # press ENTER to accept default
Enter passphrase (empty for no passphrase):                                # press ENTER for no pass phrase
Enter same passphrase again:                                               # press ENTER again
Your identification has been saved in /home/kauffman/.ssh/id_rsa           # NOTE: If prompted with "want to overwrite file .ssh/id_rsa??"
Your public key has been saved in /home/kauffman/.ssh/id_rsa.pub           #       you can cancel and proceed to the next command
The key fingerprint is:
...

&gt;&gt; ssh-copy-id csel-radish.cselabs.umn.edu                                 # enable login based on key without password
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/kauffman/.ssh/id_rsa.pub"
The authenticity of host 'csel-radish.cselabs.umn.edu (128.101.34.61)' cant be established.
RSA key fingerprint is SHA256:UXK/o93Meuq5C0hMgkaZkRZi9otBOZWncDJrm46xA+Y.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes   # type "yes" if prompted
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
Password:                                                                  # Enter X500 password
Duo two-factor login for kauffman
Enter a passcode or select one of the following options:
 1. Duo Push to XXX-XXX-XXXX
 2. Phone call to XXX-XXX-XXXX
Passcode or option (1-2): 1                                                # enter preferred option to Duo Authenticate

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh 'csel-radish.cselabs.umn.edu'"
and check to make sure that only the key(s) you wanted were added.

&gt;&gt; ssh csel-radish.cselabs.umn.edu                                         # as indicated, try logging
----------------------------------------------------------------------
       COLLEGE OF SCIENCE AND ENGINEERING WORKSTATION
...                                                                        # no password required: authenticated via public/private key
csel-radish [~]% exit                                                      # exit this shell to return to carrot
logout
Connection to csel-radish.cselabs.umn.edu closed.

&gt;&gt; chmod u+x host-add-veggie.sh                                            # ensure host-adding script is executable

&gt;&gt; ./host-add-veggie.sh                                                    # run host-adding script
Warning: Permanently added 'csel-broccoli.cselabs.umn.edu' (RSA) to the list of known hosts.
Done : csel-broccoli.cselabs.umn.edu
Warning: Permanently added 'csel-carrot.cselabs.umn.edu,128.101.34.62' (RSA) to the list of known hosts.
Done : csel-carrot.cselabs.umn.edu
Warning: Permanently added 'csel-potato.cselabs.umn.edu,128.101.34.64' (RSA) to the list of known hosts.
Done : csel-potato.cselabs.umn.edu
Done : csel-radish.cselabs.umn.edu
Warning: Permanently added 'csel-spinach.cselabs.umn.edu,128.101.34.63' (RSA) to the list of known hosts.
Done : csel-spinach.cselabs.umn.edu

&gt;&gt; ./heat-run-jobs.sh                                                      # verify that timing script runs
Output stored in the file 'heat-timings.Tue_14_Dec_2021_03:06:33_PM_CST.log'
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 1 ./heat_mpi 500 6400 0
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 2 ./heat_mpi 500 6400 0
...
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org4a571f3" class="outline-2">
<h2 id="org4a571f3"><span class="section-number-2">6</span> Page Rank</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org037f922" class="outline-3">
<h3 id="org037f922"><span class="section-number-3">6.1</span> Overview of Computing Pageranks</h3>
<div class="outline-text-3" id="text-6-1">
<p>
A key to Google's early success was its ability of its search engine
to identify web pages which seemed important to user search queries.
A key component of their engine was and remains an importance metric
metric called <a href="https://en.wikipedia.org/wiki/PageRank">Pagerank</a>, so named due to its ranking a web page and the
author of the algorithm is Larry Page (history is has a splendid sense
of irony).  The pagerank has a beautiful theory behind it which
involves modeling web users as random walkers through hyperlinked
pages. On arriving at a page, a user randomly selects a link and
visits it. This process is repeated on the next page, and the next
page, and so forth. With a small probability, a user may randomly jump
to some arbitrary other page which is not linked to the present one.
According to this formalism, pagerank represents the probability of
finding a user on a given page at a particular moment in time.  A page
with many incoming links to it has a higher probability of being
visited as many other pages have "voted" for its importance.  A page
with many outgoing links contributes little to importance of any
linked pages: its votes are spread very thin.  This rough sort of
voting turned out to be a good measure of the importance of page, at
least in the early 2000s before <a href="https://en.wikipedia.org/wiki/Google_bomb">web denizens learned to manipulate the
algorithm</a>.
</p>

<p>
It turns out that if the network of links web pages is represented as
a certain matrix, the page ranks are identical to a particular
eigenvector of that matrix.  There are several interesting facets to
this relationship for the mathematically inclined and good reading on
the subject comes from <a href="http://snap.stanford.edu/class/cs224w-readings/berkhin05pagerank.pdf">a survey by Bherkin</a>. The bottom line is that
any algorithms for computing an eigenvector of a matrix can be used to
compute page ranks.  A classical iterative technique to compute
eigenvectors is the <a href="https://en.wikipedia.org/wiki/Power_iteration">Power Method</a> which involves repeatedly multiplying
a vector by a matrix. Matrix-vector multiplication is a ripe operation
for parallelization and your primary task will be to parallelize this
process for the pagerank computation.
</p>

<p>
A code is provided called <code>dense_pagerank_serial.c</code> which performs pagerank
serial computations.  In high-level terms the computation breaks down
as follows.
</p>
<ol class="org-ol">
<li><b>Load data</b> for a matrix of web page links (<b>link matrix</b>).  Each
page is numbered 0 to <code>N-1</code> where <code>N</code> is the total number of pages.
The file format is simply pairs of numbers of one page pointing to
another one.  Loading the file involves allocating memory for the
entire matrix, zeroing each entry, then filling a 1 into each
row/col entry indicated by the file.</li>
<li><b>Normalize columns</b> by summing each column in the matrix, then
dividing each entry in a column by the sum of the column.</li>
<li><b>Apply a damping factor</b> which allows random warping from one page
to another.  The math on this is a little funky, but the intent is
to make each nonzero entry in the matrix a little smaller and each
zero entry nonzero so there is a chance of jumping to an arbitrary
page.  See the code for the specific math involved with the
update. A typical damping factor is 0.85: 85% chance of visiting a
link on the page and 15% change of jumping an arbitrary unlinked
page. This modifies the initial Link matrix once at the beginning
of the pagerank calculation.</li>
<li><b>Initialize pageranks</b> to be equal for each page and so that the
pageranks sum to 1.  If there are 10 pages, each page initially has
a pagerank of 0.1; with 100 pages each has 0.01.  Only the relative
size between ranks is important.</li>
<li><b>Multiply the link matrix by the pageranks</b> according to the
standard matrix-vector multiplication algorithm.  Store the results
in a second array of numbers.  This second array of numbers is now
the <b>new pageranks</b>.  Assign this back to the array of old
pageranks after checking for convergence.</li>
<li><b>Repeat step 5</b> of creating new pageranks by multiplying the link
matrix by the old pageranks.  Continue repeating this until there
is very little change between new and old pageranks.  At this
point, the solution has converged.</li>
</ol>

<p>
This algorithm is a good example of iterative algorithms: it is not
known ahead of time how many steps will be required to converge but
steady progress should be made as indicated by the old and new
pagerank vectors being closer and closer together.
</p>

<p>
Note that due to the columns of the link matrix and the vector of
pageranks being positive and summing to 1, the results of their
multiplication should also sum to 1 (e.g. the new pageranks also sum
to 1).  The code presently reports the <b>norm</b> of the vector as this
sum and it should remain 1 throughout the computation.
</p>

<p>
It should be mentioned that the provided code is a <b>dense</b> version of
the pagerank: every element of the link matrix has memory allocated to
it.  Unsurprisingly, a production version of the code would use
<b>sparse</b> matrices instead where the many zero entries of the matrix
are represented implicitly to save a tremendous amount of memory.
While the dense algorithm is easier to parallelize than the sparse,
the dense version is woefully inappropriate for the enormous size of
Google-scale pagerank computations involving 30,000,000,000,000+ web
pages. It is a computation that necessitates parallelism at a
sickening scale but is reasonably approximated by the present code.
</p>

<p>
Take some time to examine the code provided carefully. 
</p>
</div>
</div>

<div id="outline-container-org2768664" class="outline-3">
<h3 id="org2768664"><span class="section-number-3">6.2</span> Sample Runs of <code>dense_pagerank_serial.c</code></h3>
<div class="outline-text-3" id="text-6-2">
<p>
Part of the code distribution includes some graph files which you can
use for experimentation and timing analysis of your code.  Each graph
is named after its size and content.  The <code>notredame</code> graphs are
derived from a real dataset of web sites in the Notre Dame domain. The
full set is <a href="http://snap.stanford.edu/data/#web">available here</a> though will require a bit of processing to
be used with this code and is extremely large for a dense pagerank
calculation.  
</p>

<p>
Start by experimenting with the small graphs like <code>tiny-20.txt</code> which
has only 20 nodes in it and 200 links between pages.
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ls graphs/*.txt
graphs/notredame-100.txt    graphs/notredame-2000.txt  graphs/notredame-8000.txt
graphs/notredame-16000.txt  graphs/notredame-501.txt   graphs/tiny-20.txt

&gt;&gt; make dense_pagerank_serial 
gcc -g -Wall -o dense_pagerank_serial dense_pagerank_serial.c densemat.c -lm

&gt;&gt; dense_pagerank_serial graphs/tiny-20.txt 0.85 
Loaded graphs/tiny-20.txt: 20 rows, 200 nonzeros
Beginning Computation

ITER     DIFF     NORM
  1: 1.78e-01 1.00e+00
  2: 3.85e-02 1.00e+00
  3: 7.27e-03 1.00e+00
  4: 1.32e-03 1.00e+00
  5: 2.12e-04 1.00e+00
CONVERGED

PAGE RANKS
0.04779640
0.04147775
0.04912589
0.03965692
0.05845908
0.04394957
0.02513647
0.04369224
0.05522195
0.07147504
0.05889092
0.06569723
0.05264261
0.03913282
0.05423814
0.05833793
0.04308603
0.06827848
0.03697897
0.04672553
</pre>
</div>

<p>
The progress at each iteration is reported: the <code>DIFF</code> column should
get progressively smaller while the <code>NORM</code> column should remain 1
throughout.  After convergence, the pageranks of the 20 pages are
printed.
</p>

<p>
The largest graph you should work with is <code>notredame-8000.txt</code>
which has 8000 web sites involved in it leading to an 8000 by 8000
link matrix.  Running this through the serial code looks like the
following.  Note that the output will be long (8000+ lines) so it is
put into the file <code>output.txt</code> and examined using the <code>head</code> command
to display the first few lines.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ls graphs/*.txt
graphs/notredame-100.txt    graphs/notredame-2000.txt  graphs/notredame-8000.txt
graphs/notredame-16000.txt  graphs/notredame-501.txt   graphs/tiny-20.txt

&gt;&gt; dense_pagerank_serial graphs/notredame-8000.txt 0.85 &gt; output.txt
&gt;&gt; head -50 output.txt
Loaded graphs/notredame-8000.txt: 8000 rows, 27147 nonzeros
Beginning Computation

ITER     DIFF     NORM
  1: 1.26e+00 1.00e+00
  2: 7.92e-01 1.00e+00
  3: 4.24e-01 1.00e+00
  4: 2.48e-01 1.00e+00
  5: 1.50e-01 1.00e+00
  6: 9.45e-02 1.00e+00
  7: 6.23e-02 1.00e+00
  8: 4.11e-02 1.00e+00
  9: 2.73e-02 1.00e+00
 10: 1.91e-02 1.00e+00
 11: 1.31e-02 1.00e+00
 12: 9.24e-03 1.00e+00
 13: 6.74e-03 1.00e+00
 14: 4.91e-03 1.00e+00
 15: 3.75e-03 1.00e+00
 16: 2.81e-03 1.00e+00
 17: 2.16e-03 1.00e+00
 18: 1.64e-03 1.00e+00
 19: 1.27e-03 1.00e+00
 20: 9.79e-04 1.00e+00
CONVERGED

PAGE RANKS
0.00227804
0.00044506
0.00001875
0.00051994
0.00156742
0.00015092
0.00087703
0.00111392
0.00123884
0.00081005
0.00252026
0.00359624
0.00007052
...
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org8bcdfa1" class="outline-2">
<h2 id="org8bcdfa1"><span class="section-number-2">7</span> <b>Problem 2</b>: MPI PageRank (50%)</h2>
<div class="outline-text-2" id="text-7">
<p>
Parallelize the provided <code>dense_pagerank_serial.c</code> code for
distributed systems. Call your code <code>dense_pagerank_mpi.c</code> as this is
the convention that is supported by provided <code>Makefile</code>.
</p>
</div>

<div id="outline-container-orgc7b7591" class="outline-3">
<h3 id="orgc7b7591"><span class="section-number-3">7.1</span> Reading Data Files</h3>
<div class="outline-text-3" id="text-7-1">
<p>
The program starts with reading input from a file which should be done
only on the root processor.  After reading the whole matrix into the
root processor, send chunks of the matrix to each processor for
the main part of the algorithm.
</p>

<p>
The serial code uses a <code>densemat_t</code> structure to store the matrix.
This structure uses a trick.
</p>
<ul class="org-ul">
<li>All elements are stored in a linear array called <code>all</code>.  This allows
linear index access via <code>mat-&gt;all[i]</code></li>
<li>An array of pointers called <code>data</code> points to the beginning of each
row in the matrix. This allows row/col access via <code>mat-&gt;data[r][c]</code>.</li>
<li>As a consequence of the linear array, sequential rows are stored in
adjacent memory. In a 10 by 10 matrix, rows 0, 1, and 2 are stored
in elements 0-29 of <code>mat-&gt;all</code>.  This makes it possible to send
multiple adjacent rows with single communications.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd871c4d" class="outline-3">
<h3 id="orgd871c4d"><span class="section-number-3">7.2</span> Row Partitioning Woes</h3>
<div class="outline-text-3" id="text-7-2">
<p>
The main source of parallelism is obtained by dividing up the link
matrix so that each processor owns a collection of whole rows.  This
is effective as matrix vector multiplication relies on multiplying a
whole row by a column vector (the pageranks in this case).  
</p>

<p>
<b>Do not assume</b> that the number of rows in the link matrix is evenly
divisible by the number of processors.  Make your code more flexible
than that.  This, unfortunately, means dealing with some minutia as
not every processor will send or receive the same number of elements.
As a suggested approach, do the following
</p>
<ul class="org-ul">
<li>First, assume the number of rows is evenly divisible by the number
of processors and use simple MPI calls like <code>MPI_Scatter</code> and
<code>MPI_Allgather</code> which assume every processor will receive the same
number of elements.  Make sure that this version works on some of
the input graphs for numbers of processors that evenly divide the
size.</li>
<li>When you are confident in your code above, make a backup copy of it
for safekeeping.</li>
<li>Now take the plunge and switch to the MPI vector calls which allow
one to specify then number of elements each processor will receive:
functions like <code>MPI_Scatterv</code> and <code>MPI_Allgatherv</code> (notice the <code>v</code>
at the end) take additional parameter arrays of the counts of
elements for each processor and the offsets into storage arrays
where those elements reside.  These more complex invocation may seem
tedious, but all that is really required is to set up arrays
indicating the counts elements on each processor and pass those in.
Establish these arrays near the beginning of the program and use
them throughout.</li>
</ul>
</div>
</div>

<div id="outline-container-org1b00484" class="outline-3">
<h3 id="org1b00484"><span class="section-number-3">7.3</span> Parallelizing Column Normalization and Damping</h3>
<div class="outline-text-3" id="text-7-3">
<p>
It is suggested that you initially let the root processor read the
whole matrix, normalize the rows, apply the damping factor, then
scatter the matrix rows to each processor.  That way the serial code
can be used to ensure normalization and damping is correct.
</p>

<p>
Later, revisit the column normalization and damping to parallelize
it. 
</p>
<ul class="org-ul">
<li>Scatter the unnormalized link matrix rows to each process</li>
<li>Have each process compute an array of its own column sums</li>
<li>Use a all-to-all reduction so that every processor has the sums of
all columns. Investigate a good MPI function for this all-to-all
reduction and potentially use the <code>MPI_IN_PLACE</code> constant to save
yourself some allocations of buffers (the manual pages for relevant
MPI functions describe this option).</li>
<li>Have each processor divide each of its elements by the appropriate
column sum.</li>
<li>Have each processor apply the damping factor adjustment to each of
its elements.</li>
</ul>
</div>
</div>

<div id="outline-container-org4aa8fd1" class="outline-3">
<h3 id="org4aa8fd1"><span class="section-number-3">7.4</span> Parallelizing the Repeated Matrix-vector Multiplication</h3>
<div class="outline-text-3" id="text-7-4">
<p>
The main computation loop involves repeatedly multiplying the link
matrix by the vector or pageranks.  In the parallel version, each
processor has some whole rows of the link matrix. Note the
consequences of this decomposition.
</p>
<ul class="org-ul">
<li>Each processor has some link matrix rows but must have the whole
vector of old pageranks to do the multiplication</li>
<li>After completing the multiplication, each processor will contain
only part of the new pagerank vector and must communicate its
portion of to all other processors for the next multiplication to
occur.</li>
<li>After each multiplication, each processor must also share how much
its new pageranks differ from the equivalent portion of the old
pagerank vector so that all processors can determine if the
algorithm has converged.</li>
</ul>
<p>
This will involve several collective communication operations at each
iteration to share.
</p>
</div>
</div>

<div id="outline-container-orgc7f8c43" class="outline-3">
<h3 id="orgc7f8c43"><span class="section-number-3">7.5</span> Written Summary of <code>dense_pagerank_mpi</code> Results</h3>
<div class="outline-text-3" id="text-7-5">
<p>
Similar to the first problem, fill in the timing table in
<code>A2-WRITEUP.txt</code> associated with this problem and answer the questions
contained in that section.
</p>

<p>
Perform your timing on the Veggie Cluster. To speed up your filling in
the timing table, use the provided script <code>dense-pagerank-mpi-jobs.sh</code>
which will run jobs for the parameters in the timing table. One can
<code>grep</code> for the times amid the log file that is created as shown below.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ./dense-pagerank-mpi-jobs.sh                                                                                                                                
Output stored in the file 'dense-pagerank-mpi-timings.Fri_19_Nov_2021_04:16:25_PM_CST.log'                                                                                                    
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 1 ./dense_pagerank_mpi graphs/notredame-501.txt 0.85                                                        
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 4 ./dense_pagerank_mpi graphs/notredame-501.txt 0.85                                                        
mpirun  --mca opal_warn_on_missing_libcuda 0 -hostfile hostfile-veggie-ip.txt -np 10 ./dense_pagerank_mpi graphs/notredame-501.txt 0.85
...
Output stored in the file 'dense-pagerank-mpi-timings.Fri_19_Nov_2021_04:16:25_PM_CST.log'

&gt;&gt; grep runtime dense-pagerank-mpi-timings.Fri_19_Nov_2021_04:16:25_PM_CST.log
runtime: procs 1 graph notredame-501.txt realtime 1.234
runtime: procs 4 graph notredame-501.txt realtime 1.234
runtime: procs 10 graph notredame-501.txt realtime 1.234
...
</pre>
</div>
</div>
</div>

<div id="outline-container-orgd715edd" class="outline-3">
<h3 id="orgd715edd"><span class="section-number-3">7.6</span> Automated Tests for <code>dense_pagerank_mpi</code></h3>
<div class="outline-text-3" id="text-7-6">
<p>
Automated tests will be released later.
</p>

<p>
When the tests are released, you may run them with the provided
<code>Makefile</code> via the following target:
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make test-prob2
...
</pre>
</div>
</div>
</div>
<div id="outline-container-orga402221" class="outline-3 grading 50">
<h3 id="orga402221"><span class="section-number-3">7.7</span> Grading Criteria for Problem 2&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="50">50</span></span></h3>
<div class="outline-text-3" id="text-7-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Code compiles via <code>make dense_pagerank_mpi</code>, honors command line parameters on integrative runs.</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Passes automated tests via <code>make test-prob2</code> which also checks for memory problems.</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Cleanly written code with good documentation according to a Manual Inspection</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Written report includes timings table described above</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-left">Written report includes answers to discussion questions written above.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-orgeedde1a" class="outline-2">
<h2 id="orgeedde1a"><span class="section-number-2">8</span> <b>Problem 3</b>: OpenMP PageRank (25%)</h2>
<div class="outline-text-2" id="text-8">
<p>
Similar to Problem 2, in this problem create a version of
<code>dense_pagerank_serial.c</code> which is  parallelized for shared memory
systems using <b>OpenMP</b>. Call this program <code>dense_pagerank_omp.c</code> as
this will make it compatible with the provided <code>Makefile</code>.
</p>
</div>

<div id="outline-container-orgc2a1881" class="outline-3">
<h3 id="orgc2a1881"><span class="section-number-3">8.1</span> Shared Memory Implementation</h3>
<div class="outline-text-3" id="text-8-1">
<p>
It is best to start with the Serial Pagerank code and begin augmenting
loops via compiler directives.  This should prove fairly
straight-forward to do for most loops but take the following into
consideration.
</p>

<ul class="org-ul">
<li>Provide brief documentation comments for each loop that you will
parallelize</li>
<li>Pay special attention to any shared data that appears in the loops
which one must use synchronization primitives to protect. Comment
any atomic actions, critical regions, or reductions that are needed.</li>
<li>If any loops seem unworthy of parallelizing, comment on this as
well. For instance, if you are deciding to parallelize and Inner vs
and Outer loop, describe in a few lines your rationale.</li>
<li>EXCEPTION: Loops that must be serial as they produce output via
<code>printf()</code> do not need to be commented.</li>
</ul>
</div>
</div>

<div id="outline-container-org1663bdb" class="outline-3">
<h3 id="org1663bdb"><span class="section-number-3">8.2</span> Written Summary of <code>dense_pagerank_omp</code> Results</h3>
<div class="outline-text-3" id="text-8-2">
<p>
As before, add fill in the timing table provided in <code>A2-WRITEUP.txt</code>
in the section for Problem 3.  The script <code>dense-pagerank-omp.sh</code> is
provided to ease this. Run your experiments on the Veggie cluster.
</p>

<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ./dense-pagerank-omp-jobs.sh
Output stored in the file 'dense-pagerank-omp-timings.Fri_19_Nov_2021_08:44:39_PM_CST.log'
OMP_NUM_THREADS=1 ./dense_pagerank_omp graphs/notredame-501.txt 0.85
OMP_NUM_THREADS=4 ./dense_pagerank_omp graphs/notredame-501.txt 0.85
OMP_NUM_THREADS=10 ./dense_pagerank_omp graphs/notredame-501.txt 0.85
...
Output stored in the file 'dense-pagerank-omp-timings.Fri_19_Nov_2021_08:44:39_PM_CST.log'

&gt;&gt; grep runtime dense-pagerank-omp-timings.Fri_19_Nov_2021_08:44:39_PM_CST.log
runtime: procs 1 graph notredame-501.txt realtime 1.23
runtime: procs 4 graph notredame-501.txt realtime 1.23
runtime: procs 10 graph notredame-501.txt realtime 1.23
...
</pre>
</div>
</div>
</div>

<div id="outline-container-orgdf71b7a" class="outline-3">
<h3 id="orgdf71b7a"><span class="section-number-3">8.3</span> Automated Tests for <code>dense_pagerank_omp</code></h3>
<div class="outline-text-3" id="text-8-3">
<p>
Automated tests will be released later.
</p>

<p>
When the tests are released, you may run them with the provided
<code>Makefile</code> via the following target:
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make test-prob3
...
</pre>
</div>
</div>
</div>

<div id="outline-container-orgcbc353e" class="outline-3 grading 25">
<h3 id="orgcbc353e"><span class="section-number-3">8.4</span> Grading Criteria for Problem 3&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="25">25</span></span></h3>
<div class="outline-text-3" id="text-8-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Code compiles via <code>make dense_pagerank_omp</code> and passes automated tests via <code>make test-prob3</code></td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Cleanly written code with good documentation according to a Manual Inspection</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">IMPORTANT: Loop augmented with <code>#pragma</code> directives should have comments describing why</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">any special considerations such as race conditions, reductions, inner vs outer loop</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">parallelization, or other considerations. Serial Output <code>printf()</code> loops do not need to</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">be documented in this way.</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes timings table described above</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">Written report includes answers to discussion questions written above.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


<div id="outline-container-orgcfe96b6" class="outline-2">
<h2 id="orgcfe96b6"><span class="section-number-2">9</span> <a id="org56a5250"></a> Optional MAKEUP Problem 4 (15%)</h2>
<div class="outline-text-2" id="text-9">
<p>
Earlier in the class we discussed how many linear algebra problems,
from dot products to matrix factorization, have been studied for a
long while and robust, fast libraries exist which solve these. BLAS is
one of the oldest and most well-tested of these libraries and is
widely available in several forms.
</p>

<p>
For 15 points of MAKEUP credit, <b>re-implement serial dense pagerank
computations using BLAS</b>. The primary computation done in
<code>dense_pagerank_serial.c</code> is a repeated Matrix-Vector multiply which,
along with several other computations within the serial program, can
be converted to BLAS function calls rather than the hand-coded loops
in the original version.
</p>

<p>
You will need to do some reading on which functions are applicable and
how to call them. In addition, BLAS was originally a Fortran library
and it is recommended that you utilized the CBLAS interface for your
calls which follows C-like conventions and provides some other options
as well.  
</p>

<p>
<b>ADVISEMENT:</b> You will NOT write a parallel program in this problem,
just a faster, more optimized (and hopefully shorter) serial program
that computes the same thing as <code>dense_pagerank_serial.c</code>.
</p>
</div>

<div id="outline-container-org9d8cc9d" class="outline-3">
<h3 id="org9d8cc9d"><span class="section-number-3">9.1</span> BLAS Functions to Consider</h3>
<div class="outline-text-3" id="text-9-1">
<p>
Do some research on the following functions and consider if and where
they may be applicable to the Page Rank computation.
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">BLAS Name</th>
<th scope="col" class="org-left">CBLAS Name</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>ddot()</code></td>
<td class="org-left"><code>cblas_ddot()</code></td>
</tr>

<tr>
<td class="org-left"><code>daxpy()</code></td>
<td class="org-left"><code>cblas_daxpy()</code></td>
</tr>

<tr>
<td class="org-left"><code>dscal()</code></td>
<td class="org-left"><code>cblas_dscal()</code></td>
</tr>

<tr>
<td class="org-left"><code>dnrm2()</code></td>
<td class="org-left"><code>cblas_dnrm2()</code></td>
</tr>

<tr>
<td class="org-left"><code>dasum()</code></td>
<td class="org-left"><code>cblas_dasum()</code></td>
</tr>

<tr>
<td class="org-left"><code>dgemv()</code></td>
<td class="org-left"><code>cblas_dgemv()</code></td>
</tr>

<tr>
<td class="org-left"><code>dsymv()</code></td>
<td class="org-left"><code>cblas_dsymv()</code></td>
</tr>

<tr>
<td class="org-left"><code>dgemm()</code></td>
<td class="org-left"><code>cblas_dgemm()</code></td>
</tr>

<tr>
<td class="org-left"><code>dsymm()</code></td>
<td class="org-left"><code>cblas_dsymm()</code></td>
</tr>
</tbody>
</table>
<p>
<b>Note</b>: I used some of these routines in my implementation but not all
of them. You will want to do some reading to find the most applicable
routines and how to use them.
</p>

<ul class="org-ul">
<li>Good documentation of all BLAS functions in Fortran with selectable
types, descriptions of arguments + functionality
<a href="https://www.hpc.nec/documents/sdk/SDK_NLC/UsersGuide/blas/f/en/index.html">https://www.hpc.nec/documents/sdk/SDK_NLC/UsersGuide/blas/f/en/index.html</a></li>
<li>List of all CBLAS functions with prototypes only
<a href="http://manpages.ubuntu.com/manpages/xenial/man3/cblas.h.3.html">http://manpages.ubuntu.com/manpages/xenial/man3/cblas.h.3.html</a></li>
</ul>

<p>
Part of score for the problem will be based on utilizing BLAS routines
for as many parts of the computation as possible.  Replacing ONLY the
matrix-vector multiply will NOT earn full credit so look for other
opportunities to utilize BLAS routines such as column normalization.
</p>

<p>
<b>Document your code</b> where you are using BLAS routines to perform
computations. Your grader and <a href="http://www.catb.org/~esr/writings/unix-koans/prodigy.html">your future selves</a> will thank you.
</p>
</div>
</div>

<div id="outline-container-org9f42e58" class="outline-3">
<h3 id="org9f42e58"><span class="section-number-3">9.2</span> Building the Code</h3>
<div class="outline-text-3" id="text-9-2">
<p>
Add the following targets to your <code>Makefile</code>
</p>
<div class="org-src-container">
<pre class="src src-makefile">################################################################################
# Problem 4 : pagerank blas
prob4: dense_pagerank_blas

# build using standard blas library common to Ubuntu Linux
dense_pagerank_blas : dense_pagerank_blas.c densemat.c
	$(GCC) -o $@ $^ -lm -lblas

# build using optimized blas library on CSE Labs
prob4-atlas : 			
	rm -f dense_pagerank_blas
	$(GCC) -o dense_pagerank_blas dense_pagerank_blas.c densemat.c -lm /usr/lib/x86_64-linux-gnu/libcblas.so.3.10.3 

# build using cblas library common to Arch Linux
prob4-cblas : 			
	rm -f dense_pagerank_blas
	$(GCC) -o dense_pagerank_blas dense_pagerank_blas.c densemat.c -lm -lcblas

test-prob4: test-setup dense_pagerank_blas
	./testy test_dense_pagerank_blas.org $(testnum)
</pre>
</div>

<p>
Note that you should name your source file <code>dense_pagerank_blas.c</code> and
the resulting program will be named <code>dense_pagerank_blas</code>. However,
there is some variance in libraries and linking procedures for BLAS
libraries.
</p>
<ol class="org-ol">
<li>The default <code>-lblas</code> for the first build target above will work on
most Ubuntu Linux distributions presuming that the BLAS library is
installed. <code>libblas</code> contains CBLAS functions in it but all the
functions are reference implementations so may not run as fast as
possible.</li>
<li><p>
CSE Labs machines has the <a href="http://math-atlas.sourceforge.net/">ATLAS</a> implementation of BLAS (partially)
installed. This version is tuned to hardware and is therefore much
faster than the untuned versions. To build this version on CSE Labs
run
</p>
<pre class="example">
&gt;&gt; make prob4-atlas
</pre>

<p>
<b>Use <code>make prob4-atlas</code> before timing on the Veggie Cluster</b> with
the provided timing script.
</p></li>
<li><p>
Some Linux distributions have separate libraries for both BLAS and
CBLAS and require linking <code>libcblas</code>. The final target is used for
these cases and is invoked via
</p>
<pre class="example">
&gt;&gt; make prob4-cblas
</pre>

<p>
but should only be used for testing on local machines as it will
not work on CSE Labs.
</p></li>
</ol>
</div>
</div>

<div id="outline-container-org4f41fc2" class="outline-3">
<h3 id="org4f41fc2"><span class="section-number-3">9.3</span> Testing and Timing</h3>
<div class="outline-text-3" id="text-9-3">
<p>
A small set of test cases are provided which will verify that the BLAS
version <code>dense_pagerank_blas</code> produces identical output to the
standard serial version <code>dense_pagerank_serial</code>. These can be run with
the target
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; make test-prob4
</pre>
</div>
<p>
which is NOT done on Gradescope but will be run manually.
</p>

<p>
A timing script <code>dense-pagerank-blas-jobs.sh</code> is provided that will
produce timing results for both the serial and BLAS versions of the
code. These will be reported in <code>A2-WRITEUP.txt</code>.
</p>

<p>
<b>When timing your code on CSE Labs</b> use the following commands to
ensure that you compile with the fastest BLAS library and observe its
behavior. 
</p>
<div class="org-src-container">
<pre class="src src-sh">&gt;&gt; ssh csel-carrot.cselabs.umn.edu
...
carrot [a2-code] % make prob4-atlas
rm -f dense_pagerank_blas
gcc -g -Wall  -o dense_pagerank_blas dense_pagerank_blas.c densemat.c -lm /usr/lib/x86_64-linux-gnu/libcblas.so.3.10.3 

carrot [a2-code] % ./dense-pagerank-blas-jobs.sh 
Output stored in the file 'dense-pagerank-blas-timings.Tue_07_Dec_2021_03:32:07_PM_CST.log'
./dense_pagerank_serial graphs/notredame-501.txt 0.85
./dense_pagerank_blas graphs/notredame-501.txt 0.85
...

carrot [a2-code] % grep runtime dense-pagerank-blas-timings.*.log
./dense_pagerank_serial graph notredame-501.txt realtime ...
./dense_pagerank_blas graph notredame-501.txt realtime ...
</pre>
</div>

<p>
Fill in the following timing table based on running the provided
script <code>dense-pagerank-blas-jobs.sh</code>.
</p>
<div class="org-src-container">
<pre class="src src-text">  -----------------------------
                   size        
   Procs     501   8000  16000 
  -----------------------------
   serial  00.00  00.00  00.00 
   blas    00.00  00.00  00.00 
  -----------------------------
</pre>
</div>
</div>
</div>

<div id="outline-container-org24b4b60" class="outline-3 grading 15">
<h3 id="org24b4b60"><span class="section-number-3">9.4</span> Grading Criteria for Problem 4&#xa0;&#xa0;&#xa0;<span class="tag"><span class="grading">grading</span>&#xa0;<span class="15">15</span></span></h3>
<div class="outline-text-3" id="text-9-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">CRITERIA</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">5</td>
<td class="org-left">Code compiles via <code>make dense_pagerank_blas</code> and passes automated tests via <code>make test-prob4</code></td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left">DOCUMENTATION of which parts of the computation have been converted to use BLAS routines.</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">Points will be lost if BLAS has been used minimally to perform few parts of the computation.</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-left"><code>A2-WRITEUPT.xt</code> has the timing table for standard serial and BLAS from the job running script.</td>
</tr>

<tr>
<td class="org-right">&#xa0;</td>
<td class="org-left">Times seem to reflect use of the ATLAS BLAS implementation which is produced via <code>make prob4-atlas</code></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-org7fce424" class="outline-2">
<h2 id="org7fce424"><span class="section-number-2">10</span> Project Submission on Gradescope</h2>
<div class="outline-text-2" id="text-10">
<p>
NOTE 1: Submission to Gradescope is not yet open; follow the
instructions in this section when it opens.
</p>

<p>
NOTE 2: The instructions below pertain to another class and some of
the pictures mention "project" and <code>p1-code</code> which in our case is
"assignment" and <code>a2-code</code>.  The instructions apply nonetheless and
boil down to:
</p>
<ol class="org-ol">
<li>Create a zip of your assignment code via <code>make zip</code></li>
<li>Upload the code to Gradescope</li>
<li>Check that the automated tests that run on Gradescope match you
expectations.</li>
<li>Add you partner to your submission. Only one partner should submit
the code.</li>
</ol>
</div>

<div id="outline-container-orged0d582" class="outline-3">
<h3 id="orged0d582"><span class="section-number-3">10.1</span> <a id="org8e027a6"></a> Submit to Gradescope</h3>
<div class="outline-text-3" id="text-10-1">
<p>
Some of the pictures below mention 'Assignment' which is now 'Project'
and may mention some files that are not part of the current
project. The process of uploading submission is otherwise the same.
</p>

<ol class="org-ol">
<li><p>
In a terminal, change to your project code directory and type <b>make
zip</b> which will create a zip file of your code. A session should
look like this:
</p>
<div class="org-src-container">
<pre class="src src-sh">   &gt; cd Desktop/5451/a2-code      # location of assignment code

   &gt; ls 
   Makefile    dense_pagerank_mpi.c    heat_serial.c
   ...

   &gt; make zip                     # create a zip file using Makefile target
   rm -f a2-code.zip
   cd .. &amp;&amp; zip "a2-code/p1-code.zip" -r "a2-code"
     adding: a2-code/ (stored 0%)
     adding: a2-code/Makefile (deflated 68%)
     adding: a2-code/dense_pagerank_mpi.c (deflated 69%)
     adding: a2-code/test_dense_pagerank_mpi.org (deflated 71%)
     ...
   Zip created in a2-code.zip

   &gt; ls a2-code.zip
   a2-code.zip
</pre>
</div></li>
<li><p>
Log into <a href="https://www.gradescope.com/">Gradescope</a> and locate and click 'Assignment 2' which will
open up submission
</p>
<div class="org-center">

<div id="org8e78405" class="figure">
<p><img src="gradescope01.png" alt="gradescope01.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
Click on the 'Drag and Drop' text which will open a file selection
dialog; locate and choose your <code>a2-code.zip</code> file
</p>
<div class="org-center">

<div id="org09012b3" class="figure">
<p><img src="gradescope02.png" alt="gradescope02.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
This will show the contents of the Zip file and should include your
C source files along with testing files and directories. 
</p>
<div class="org-center">

<div id="org27540d8" class="figure">
<p><img src="gradescope03.png" alt="gradescope03.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
Click 'Upload' which will show progress uploading files.  It may
take a few seconds before this dialog closes to indicate that the
upload is successful. Note: there is a limit of 256 files per
upload; normal submissions are not likely to have problems with
this but you may want to make sure that nothing has gone wrong such
as infinite loops creating many files or incredibly large files. 
</p>

<p>
<b>WARNING</b>: There is a limit of 256 files per zip. Doing <code>make zip</code>
will warn if this limit is exceeded but uploading to Gradescope
will fail without any helpful messages if you upload more the 256
files in a zip. 
</p>

<div class="org-center">

<div id="org10f07b4" class="figure">
<p><img src="gradescope04.png" alt="gradescope04.png" style="max-width:100%;" />
</p>
</div>
</div></li>

<li><p>
Once files have successfully uploaded, the Autograder will begin
running the command line tests and recording results.  These are
the same tests that are run via <code>make test</code>.   
</p>
<div class="org-center">

<div id="org91754ec" class="figure">
<p><img src="gradescope05.png" alt="gradescope05.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><p>
When the tests have completed, results will be displayed
summarizing scores along with output for each batch of tests.
</p>
<div class="org-center">

<div id="orgfbcc3d4" class="figure">
<p><img src="gradescope06.png" alt="gradescope06.png" style="max-width:100%;" />
</p>
</div>
</div></li>
<li><b>Don't forget to add you partner to your submission</b> after
uploading. Only one partner needs to submit the code.</li>
</ol>
</div>
</div>

<div id="outline-container-orgf9d817b" class="outline-3">
<h3 id="orgf9d817b"><span class="section-number-3">10.2</span> Late Policies</h3>
<div class="outline-text-3" id="text-10-2">
<p>
You may wish to review the policy on late project submission which
will cost 1 Engagement Point per day late. <b>No projects will be
accepted more than 48 hours after the deadline.</b>
</p>

<p>
<a href="https://www-users.cs.umn.edu/~kauffman/5451/syllabus.html">https://www-users.cs.umn.edu/~kauffman/5451/syllabus.html</a>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr/> <i> Author: Chris Kauffman (<a href="mailto:kauffman@umn.edu">kauffman@umn.edu</a>) <br/> Date: 2021-12-14 Tue 15:16 <br/> </i>
</div>
</body>
</html>
